<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>&#8216;Q i-jtb the Raven&#8217;: Taking Dirty OCR Seriously | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/qijtb-the-raven-mla/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">‚ÄòQ i-jtb the Raven‚Äô: Taking Dirty OCR Seriously</h1> <p class="post-meta">January 7, 2016</p> <p class="post-tags"> <a href="/blog/2016"> <i class="fas fa-calendar fa-sm"></i> 2016 </a> </p> </header> <article class="post-content"> <p><em>The following is a talk I will deliver on January 9, 2016 for the Bibliography and Scholarly Editing Forum‚Äôs panel at <a href="https://www.mla.org/Convention/MLA-2016" target="_blank" rel="noopener noreferrer">MLA 2016</a>. It is part of a longer article in progress.</em></p> <p>On November 28, 1849 the <a href="chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/"><em>Lewisburg Chronicle, and the West Branch Farmer</em></a> published one of the most popular poems of the nineteenth century, Edgar Allan Poe‚Äôs ‚ÄúThe Raven.‚Äù</p> <p><a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/" target="_blank" rel="noopener noreferrer"><img src="/img/pasted-image-small-67.png" alt="The November 28, 1849 Lewisburg Chronicle, and the West Branch Farmer"></a></p> <p><em>The November 28, 1849 Lewisburg Chronicle, and the West Branch Farmer</em></p> <p>The <em>Lewisburg Chronicle</em>‚Äôs ‚ÄúRaven‚Äù is one version among many printed after Poe‚Äôs death in 1849‚Äî‚ÄúBy Edgar A. Poe, dec‚Äôd‚Äù‚Äîinteresting as a small signal of the poem‚Äôs circulation and reception. It is just such reprinting that we are tracing in <a href="http://viraltexts.org" target="_blank" rel="noopener noreferrer">the Viral Texts project</a>, in which we use computational methods to automatically surface patterns of reprinting across nineteenth-century newspaper archives.</p> <p>And so this version of the poem also becomes interesting as a digitized object in the twenty-first century, in which at least one iteration of the poem‚Äôs famous refrain is rendered by optical character recognition as, ‚ÄúQ i-jtb the Raven, ‚ÄòNevermore‚Äô‚Äù (OCR is a term for computer programs that identify machine-readable words from a scanned page image, and is the source for most of the searchable data in large-scale digital archives). What is <em>this</em> text‚Äîthis digital artifact I access in 2016? Where did it come from, and how did it come to be?</p> <p>Such questions are particularly acute as researchers increasingly leverage digitized archives through computational text and image analysis. As a complement to such analyses we require more robust methods for describing digital artifacts bibliographically: accounting for the sources, technologies, and social realities of their creation in ways that make their affordances and limitations more readily visible and available for critique. Matthew Kirschenbaum has named such practices ‚Äúforensics,‚Äù while Bonnie Mak has suggested ‚Äúan archaeology that excavates for consideration the discursive practices by which digitizations are produced, circulated, and received.‚Äù<a id="fnref:1" class="footnote" title="see footnote" href="#fn:1">[1]</a><a id="fnref:2" class="footnote" title="see footnote" href="#fn:2">[2]</a></p> <p><a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/ocr/" target="_blank" rel="noopener noreferrer"><img src="/img/pasted-image-200.png" alt="A sample of the OCR-derived text for ‚ÄúThe Raven‚Äù in the CA Lewisburg Chronicle, including the line that gives this talk its title." width="100%"></a></p> <p><em>A sample of the OCR-derived text for ‚ÄúThe Raven‚Äù in the CA Lewisburg Chronicle, including the line that gives this talk its title.</em></p> <p>Discussions of large-scale digital text archives inevitably return to the question of the OCR-derived text data that underlies them. Depending on the type, age, and conditions of its given historical texts, as well as on the procedures, hardware, and software of their digitization, OCR quality in large-scale archives ranges widely. The consequences of ‚Äúerrorful‚Äù OCR files, to borrow a term from computer science, influence our research in ways by now well expounded by humanities scholars, inhibiting, for instance, comprehensive search. Were I to search ‚ÄúQuoth the Raven‚Äù in the Chronicling America database, its search engine would not find the line that gives me my title. However, critiques that both begin and end with the imperfections of the digitized text signal a foreshortening of the bibliographic imagination, in which the digital archive can be only a transparent window into the ‚Äúactual,‚Äù material objects of study.</p> <p>Our primary perspective on the digitized text thus far has been that of the textual critic who is entirely ‚Äúconcerned with‚Ä¶the reconstruction of the author‚Äôs original text.‚Äù As W. W. Greg contended in 1932, however, ‚Äúcriticism may just as rightly be applied to any other point in the transmission of the text.‚Äù For Greg, the bibliographer‚Äôs concern must be ‚Äúthe whole history of the text‚Äù in which ‚Äúthe author‚Äôs original is but one step‚Äù‚Äîalbeit likely an important step‚Äî‚Äúin the transmission.‚Äù Greg describes ‚Äúthe text‚Äù not as a single individual, but instead as a lineage:</p> <blockquote>We have in fact to recognize that a text is‚Ä¶a living organism which in its descent through the ages, while it departs more and more from the form impressed upon it by its original author, exerts, through its imperfections as much as through its perfections, its own influence upon its surroundings.<a id="fnref:3" class="footnote" title="see footnote" href="#fn:3">[3]</a> </blockquote> <p>In the five decades since its publication, Greg‚Äôs notion of the text has significantly influenced work in bibliography, book history, and even critical editing. Theories of the variorium text, the fluid text, and the social text have refined a vocabulary for discussing transmission, circulation, and difference as essential features of any literary work. Scholars have experimented with ways to represent fungible texts both in print, such as <a href="http://www.pearsonhighered.com/educator/product/Moby-Dick-A-Longman-Critical-Edition/9780321228000.page" target="_blank" rel="noopener noreferrer">John Bryant‚Äôs ‚Äúfluid text‚Äù edition of <em>Moby-Dick</em></a> (Longman 2009), and using digital tools, such as NINES‚Äô <a href="http://juxtacommons.org/" target="_blank" rel="noopener noreferrer">Juxta Commons collation platform</a>.<a id="fnref:4" class="footnote" title="see footnote" href="#fn:4">[4]</a> While scholars revel in revealing the fluidity of texts from the hand- and machine-press eras, however, we rarely note‚Äîexcept, perhaps, to dismiss them‚Äîthe variora emerging online. Just as cheap, pirated, and errorful American editions of nineteenth-century British novels now teach scholars much about the economics, print technology, and literary culture in that period, dirty OCR illuminates the priorities, infrastructure, and economics of the academy in the late 20th and early 21st centuries.</p> <p>There is a growing body of literature around the bibliographic description of born digital materials, such as Kirschenbaum‚Äôs analysis of William Gibson‚Äôs electronic poem <em>Agrippa</em> in <em><a href="https://mitpress.mit.edu/books/mechanisms" target="_blank" rel="noopener noreferrer">Mechanisms</a></em>, or the ‚ÄúPreserving Virtual Worlds‚Äù team‚Äôs attempts to <a href="http://www.digitalhumanities.org/dhq/vol/4/2/000089/000089.html" target="_blank" rel="noopener noreferrer">apply a FRBR (functional requirements for bibliographic records) model to classic computer games</a> such as <em>Mystery House</em>, <em>ADVENTURE</em>, and <em>Spacewar!</em> The PVW team notes that ‚Äúeven the simplest electronic ‚Äòtext‚Äô is in fact a composite of many different symbolic layers‚Äù and the same is true of the digitized historical text.<a id="fnref:5" class="footnote" title="see footnote" href="#fn:5">[5]</a></p> <p>The mass-digitized book, newspaper, or magazine is never simply a transparent surrogate for a corresponding physical object. It is instead a new edition‚Äîin the full bibliographic sense of the word‚Äîwhich, while it ‚Äúdeparts more and more from the form impressed upon it by its original author,‚Äù nonetheless ‚Äùexerts, through its imperfections as much as through its perfections, its own influence upon its surroundings.‚Äú As Belanger describes, ‚Äú[a]n edition of a book is all copies printed at one or later times from the same setting of type.‚Äù<a id="fnref:6" class="footnote" title="see footnote" href="#fn:6">[6]</a>¬†While <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1.jp2" target="_blank" rel="noopener noreferrer">the <em>image</em> of a particular digitized text</a> provided by an archive may reflect precisely the setting of type in the edition from which it was scanned,¬†<a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/ocr/" target="_blank" rel="noopener noreferrer">the <em>computer-readable text</em></a> was created by OCR software, or ‚Äúreset,‚Äù from the image-original. We might think of OCR as a species of compositor: prone to transcription errors, certainly, but nonetheless resetting the type of its proof texts into .txt or .xml files rather than printer‚Äôs frames.</p> <p>In arguing that those text files constitute new editions, I am not particularly bothered by the fact that OCR is an ‚Äúautomatic‚Äù process, while composing type is a ‚Äúhuman‚Äù process. To maintain such a dichotomy we must both overestimate the autonomy of human compositors in print shops and underestimate the role of computer scientists in OCR. Both movable type and optical character recognition, along with a host of textual technologies in between, attempt to automate laborious aspects of textual production. Indeed, we can only speak of editions as such, whether printed or digital, within an industrialized framework. The very concept of the edition only pertains when sets of identical copies can be produced for a given book. During print‚Äôs infancy it was decried as mechanical or inhuman, as in 1492 when Johannes Trithemius claimed‚Äîin a book he promptly had printed‚Äîthat ‚ÄúPrinted books will never be the equivalent of handwritten codices, especially since printed books are often deficient in spelling and appearance. The simple reason,‚Äù Trithemius insisted, ‚Äúis that copying by hand requires more diligence and industry.‚Äù<a id="fnref:7" class="footnote" title="see footnote" href="#fn:7">[7]</a> When print was less familiar, in other words‚Äîduring the period Alan Liu might call ‚Äúthe unpredictable zone of contact‚Äù between manuscript and print culture‚Äîits errorful industrialism was as apparent to scholars as that of OCR is to us now.<a id="fnref:8" class="footnote" title="see footnote" href="#fn:8">[8]</a> Moreover, by speaking of OCR as an ‚Äúautomatic‚Äù process, we elide a substantial sub-field of research by colleagues in Computer Science. While OCR certainly <em>automates</em> certain acts of transcription, it does so following constantly-developing rules and processes devised by human scholars.<a id="fnref:9" class="footnote" title="see footnote" href="#fn:9">[9]</a></p> <p>In order to reorient ourselves toward the digitized archive, we must reckon with its constituent parts and take seriously its digitality. In my remaining time I will outline some steps toward such a method using <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/" target="_blank" rel="noopener noreferrer">the November 28, 1849 <em>Lewisburg Chronicle</em></a>, in hopes this focus will seed thinking about the larger archive from which it is drawn. While some of the steps I describe may seem self-evident, I suggest they are not to a good many scholars working in digital archives, and that even such obvious steps are elided when scholars treat‚Äîand cite‚Äîdigitized sources as transparent surrogates rather than new editions.</p> <p>1. First, CA‚Äôs interface offers relatively little information about particular newspaper issues. The only prominent metadata lists a newspaper‚Äôs name, issue date, and the image number of the displayed page. Clicking on the name of the newspaper just below the title‚Äîwhere, in this case, it reads ‚ÄúAbout Lewisburg Chronicle‚Ä¶‚Äù‚Äîbrings users to <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/" target="_blank" rel="noopener noreferrer">a longer catalogue and narrative description of the print edition of this newspaper</a>. These prose narratives were written for each CA newspaper by the awardees who digitized them‚Äîmore on awardees soon‚Äîand offer insight into the aims, audience, and affiliations of the papers.</p> <p>To glean more details about a particular newspaper‚Äôs CA digitization, users can click the link at the bottom right of a newspaper‚Äôs page‚Äîwhere it reads in this instance ‚ÄúProvided by Penn State‚Ä¶‚Äù‚Äîto learn more about the papers contributed by a specific awardee.¬†From <a href="http://chroniclingamerica.loc.gov/awardees/pst/" target="_blank" rel="noopener noreferrer">the awardees page for the Penn State University Libraries</a>, one can browse the batches they have contributed to CA and learn that the November 28, 1849 issue of the <em>Lewisburg Chronicle</em> was uploaded in <a href="http://chroniclingamerica.loc.gov/batches/batch_pst_fenske_ver02/" target="_blank" rel="noopener noreferrer">batch_pst_fenske_ver02</a> on July 9, 2013 at 8:07pm.<a id="fnref:10" class="footnote" title="see footnote" href="#fn:10">[10]</a> This metadata is all that CA provides for any given issue directly through its interface.</p> <p>2. We can learn more about the digitization process for an issue in CA by downloading its <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1.jp2" target="_blank" rel="noopener noreferrer">JPG</a> and <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1.pdf" target="_blank" rel="noopener noreferrer">PDF</a> files. While the images themselves reproduce the historical page, there is much more information about the files and their creation in their Exif (Exchangeable Image File Format) data. There are a range of methods for reading Exif data. Using the command line application <a href="http://www.sno.phy.queensu.ca/~phil/exiftool/" target="_blank" rel="noopener noreferrer">Exiftool</a> on the JPG and PDF of our sample <em>Lewisburg Chronicle</em> issue, for instance, we see the following:<a id="fnref:11" class="footnote" title="see footnote" href="#fn:11">[11]</a></p> <p><em>JPF Exif metadata</em></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ExifTool Version Number: 10.01
File Name: seq-1.jp2
Directory: .
File Size: 4.5 MB
File Modification Date/Time: 2015:12:10 15:55:47+01:00
File Access Date/Time: 2015:12:11 13:37:35+01:00
File Inode Change Date/Time: 2015:12:10 15:55:48+01:00
File Permissions: rw-r-----
File Type: JP2
File Type Extension: jp2
MIME Type: image/jp2
Major Brand: JPEG 2000 Image (.JP2)
Minor Version: 0.0.0
Compatible Brands: jp2
Image Height: 6997
Image Width: 5412
Number Of Components: 1
Bits Per Component: 8 Bits, Unsigned
Compression: JPEG 2000
Color Spec Method: Enumerated
Color Spec Precedence: 0
Color Spec Approximation: Not Specified
Color Space: Grayscale
Warning: Can't currently handle huge JPEG 2000 boxes
Image Size: 5412x6997
Megapixels: 37.9
</code></pre></div></div> <p><em>PDF Exif Metadata</em></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ryans-MacBook-Pro:downloads rcc$ exiftool seq-1.pdf
ExifTool Version Number: 10.01
File Name: seq-1.pdf
Directory: .
File Size: 826 kB
File Modification Date/Time: 2015:12:10 15:55:50+01:00
File Access Date/Time: 2015:12:10 16:10:22+01:00
File Inode Change Date/Time: 2015:12:10 15:55:55+01:00
File Permissions: rw-r-----
File Type: PDF
File Type Extension: pdf
MIME Type: application/pdf
PDF Version: 1.4
Linearized: No
Page Count: 1
Page Mode: UseNone
Format: application/pdf
Title (en): Lewisburg Chronicle, and the West Branch Farmer..(Lewisburg, Pa.) 1849-11-28 [p ].
Description (en): Page from Lewisburg Chronicle, and the West Branch Farmer. (newspaper). [See LCCN: sn85055199 for catalog record.]. Prepared on behalf of Penn State University Libraries; University Park, PA.
Date: 1849:11:28
Type: text, newspaper
Identifier: Reel number 0028077635A. Sequence number 50
Create Date: 2012:01:18 12:56:08-07:00
Producer: itext-paulo-138 (itextpdf.sf.net-lowagie.com)
Modify Date: 2012:01:18 12:56:08-07:00
</code></pre></div></div> <p>As we can see these examples, some metadata recurs in the Exif metadata for each file, while some is unique to one file or the other. In this case, the JPG‚Äôs Exif metadata mostly describes the JPG file itself: its size, resolution, color profile. The PDF Exif metadata, by contrast, details when the file was originally created, to the second (January 18, 2012); the microfilm reel from which it was scanned (Reel number 0028077635A); and even the software package that created it (itext-paulo‚Äì138). <a href="http://itextpdf.com/" target="_blank" rel="noopener noreferrer">iText is a software package </a>for managing large-scale PDF creation, and it uses the ABBYY Finereader OCR software.</p> <p>3. There is one additional image file from which scholars can glean information about CA‚Äôs digitized newspaper editions, though one must read the <a href="http://www.loc.gov/ndnp/guidelines/" target="_blank" rel="noopener noreferrer">NDNP‚Äôs Technical Guidelines</a> to realize it exists.<a id="fnref:12" class="footnote" title="see footnote" href="#fn:12">[12]</a> According to those guidelines, each issue uploaded to CA must include an archive-quality TIFF file. That latter file is not served to users as part of Chronicling America‚Äôs interface, likely because they are quite large files and it would be server-intensive for too many users to download them frequently. To obtain the archive-quality tiff of this <em>Lewisburg Chronicle</em> issue, I wrote directly to the Library of Congress; after a few days a librarian sent me a link through which I could download the TIFF.</p> <p>The TIFF file‚Äôs Exif metadata includes yet more information about how this issue was digitized and is the only place that lists the scanner model used for digitization: the Eclipse 300D microfilm scanner.<a id="fnref:13" class="footnote" title="see footnote" href="#fn:13">[13]</a></p> <p><em>TIFF Exif Metadata</em></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ExifTool Version Number: 10.01
File Name: 0050.tif
Directory: .
File Size: 36 MB
File Modification Date/Time: 2015:12:10 20:34:01+01:00
File Access Date/Time: 2015:12:11 14:25:24+01:00
File Inode Change Date/Time: 2015:12:10 20:34:01+01:00
File Permissions: rw-r-----
File Type: TIFF
File Type Extension: tif
MIME Type: image/tiff
Exif Byte Order: Little-endian (Intel, II)
Subfile Type: Single page of multi-page image
Image Width: 5409
Image Height: 6997
Bits Per Sample: 8
Compression: Uncompressed
Photometric Interpretation: BlackIsZero
Fill Order: Normal
Document Name: 0028077635A
Make: Eclipse
Camera Model Name: Eclipse 300D,SN# sn632129
Strip Offsets: 493
Orientation: Horizontal (normal)
Samples Per Pixel: 1
Rows Per Strip: 6997
Strip Byte Counts: 37846773
X Resolution: 300
Y Resolution: 300
Planar Configuration: Chunky
Resolution Unit: inches
Page Number: 0 1
Software: iArchives, Inc., 3.240
Modify Date: 2012:01:18 12:55:32
Artist: Penn State University Libraries; University Park, PA; iArchives
File Source: Unknown (microfilm)
Image Unique ID: 50
Image Size: 5409x6997
Megapixels: 37.8
</code></pre></div></div> <iframe width="560" height="315" src="https://www.youtube.com/embed/vhFjYFiLfIc" frameborder="0" allowfullscreen=""></iframe> <p>This might seem a mundane detail, but I would argue it is just as important to a full understanding of this text as knowing the printing press is to a full understanding of a printed book.</p> <p>4. Next, we can learn a few new details from the XML (eXtensible Markup Language) file of this newspaper page. The location of this file is not obvious, though one can find it on the CA website. In short, one must scroll to the bottom of the ‚ÄúText‚Äù file provided in the main menu (where the JPG and PDF can be found) where one finds a link to the XML file.<a id="fnref:14" class="footnote" title="see footnote" href="#fn:14">[14]</a> The <em>Lewisburg Chronicle</em>‚Äôs XML file includes important additional metadata about the OCR processing that generated the computable text of this edition.</p> <p><a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/1849-11-28/ed-1/seq-1/ocr.xml" target="_blank" rel="noopener noreferrer"><img src="/img/pasted-image-734.png" alt="The XML file for this edition of the Lewisburg Chronicle." width="600"></a></p> <p><em>The XML file for this edition of the Lewisburg Chronicle.</em></p> <p>These XML fields show, for instance, that the OCR was performed using the Abbyy Finereader 9 software, with a ‚ÄúPredicted Word Accuracy‚Äù of 98.2%.<a id="fnref:15" class="footnote" title="see footnote" href="#fn:15">[15]</a></p> <p>The XML also lists ‚ÄúiArchives OCR‚Äù as ‚Äúprocessing software.‚Äù This reference to iArchives points us away from Chronicling America‚Äôs interface to an institutional history largely hidden from it. iArchives is a company in Lindon, Utah <a href="http://www.iarchives.com/pr3.shtml" target="_blank" rel="noopener noreferrer">which many of the first grantees under the NDNP contracted to perform their scanning</a>. This detail in the XML file, then, indicates Penn State University Library did not digitize this newspaper issue in house.<a id="fnref:16" class="footnote" title="see footnote" href="#fn:16">[16]</a></p> <p>I would assert that the digitized edition of the November 28, 1849 <em>Lewisburg Chronicle, and the West Branch Farmer</em> comprises at least six parts: an archival TIFF, a JPG, a PDF, an OCR-derived text file, an XML file, and the web interface. The image files might be classed as a species of facsimile edition, while the OCR-derived text and XML files are a new editions; all of these come together in a kind of digital variorum. Bibliographic clues are scattered among the artifact‚Äôs parts, not all of which are available through CA‚Äôs public interface.</p> <p>The details gleaned from these files, however, are only one part of a full bibliographic account, which should also concern itself with the institutional, financial, social, and governmental structures that lead one historical textual object to be digitized, while another is not. In Ian Milligan‚Äôs study of newspapers cited in Canadian dissertations, he demonstrates quantitatively that overall citations of newspapers have increased in ‚Äúthe post-database period,‚Äù but also that those citations draw ever more disproportionately from those papers which have been digitized over those which have not: ‚ÄúBefore digitization, a newspaper like the Ottawa Citizen was roughly equivalent in historical usage to the Toronto Star, as one might expect, given their relative prominence in Canadian history. After the Star was digitized and made available, however, it became far more prominent‚Äù in dissertations.<a id="fnref:17" class="footnote" title="see footnote" href="#fn:17">[17]</a> In other words, decisions about what to digitize ripple throughout the scholarly record from then on, a phenomenon we should mark in scholarship drawn from digitized texts.</p> <p><a href="/img/pasted-image-1152.jpg" target="_blank"><img src="/img/pasted-image-1152.jpg" alt="A map of state contributions to Chronicling America, prepared by Viral Texts research assistant Abby Mullen." width="600"></a></p> <p><em>A map of state contributions to Chronicling America, prepared by Viral Texts research assistant Abby Mullen.</em></p> <p>In the case of the <em>Lewisburg Chronicle</em>, understanding the decisions that led to its digitization requires delving into a range of paratexts related to the United States‚Äô National Digital Newspaper Project (NDNP) and its grantees. By mentioning the NDNP, I highlight an essential bibliographic fact about the Chronicling America database. CA is not a single digitization project run by the Library of Congress, but the portal to data generated by the NDNP, which awards grants to groups in individual states seeking to digitize their historical newspapers. Such state-level granting, however, means that some states are well represented, others less so, while many are not represented at all. For instance, my home state of Massachusetts has not yet participated in the NDNP, meaning that CA includes no papers from Boston or other Massachusetts towns. This also means that measures of newspapers‚Äô significance vary from state to state. In their applications for NDNP funding, groups must articulate a rationale for choosing ‚Äúhistorically significant newspapers‚Äù from their state. While these rationales share many features, they are not identical.<a id="fnref:18" class="footnote" title="see footnote" href="#fn:18">[18]</a></p> <p>Penn State University Libraries was one of the first NDNP grantees and they have received two rounds of supplemental funding; they are the third largest contributor to the site. The three phases of the Pennsylvania Digital Newspaper Project (PaDNP)<a href="https://www.libraries.psu.edu/psul/digipres/panp/panp.html" target="_blank" rel="noopener noreferrer"> are described on a Penn State University Library webpage</a>, while <a href="http://www.personal.psu.edu/kkm111/blogs/pa_digital_newspaper_project/" target="_blank" rel="noopener noreferrer">Phase I</a> and <a href="http://www.personal.psu.edu/kkm111/blogs/padnp2/" target="_blank" rel="noopener noreferrer">Phase II</a> are also documented through blogs hosted at PSU.<a id="fnref:19" class="footnote" title="see footnote" href="#fn:19">[19]</a> These blogs, taken together with Penn State‚Äôs grant proposals, press releases, and NDNP program digitization guidelines, provide unique insight into the processes through the <em>Lewisburg Chronicle</em>, a rural paper from Union County, came to be collected in CA while nineteenth-century Philadelphia is represented by a single newspaper, the <em>Evening Telegraph</em>.</p> <p>In short, Penn State‚Äôs plans for digitization emphasized certain kinds of geographic and demographic representativeness over others. Under their Phase I grant of $393,650, for instance, the group digitized Pennsylvania newspapers published between 1880 and 1922. The newspapers chosen were ‚Äúcurrently on microfilm‚Äù and were selected by Penn State in consultation with the State Library of Pennsylvania and the Free Library of Philadelphia. These stakeholders used census data to identify the 10 cities with the largest populations between 1880‚Äì1922. From these cities, ‚Äú48 publications were reviewed for initial consideration, with the final selection made by an advisory board of researchers, scholars, librarians and historians.‚Äù</p> <p>Penn State‚Äôs Phase II grant of $393,489¬†expanded the project‚Äôs time frame to 1836‚Äì1922 while ‚Äútitle selection efforts focused on 17 Pennsylvania counties without any known digitized newspapers.‚Äù In Phase II they digitized 45 new titles from the State Library of Pennsylvania, the Free Library of Philadelphia, Bloomsburg University Library, and the Pennsylvania Historical and Museum Commission.</p> <p>Finally, Penn State‚Äôs Phase III grant of $321,526¬†allowed the group to digitize 109,025 pages from 39 newspapers published between 1836‚Äì1922. The foci for this round included: ‚ÄúTitles from four counties with very little or no digitization,‚Äù ‚ÄúTiles that represent the Commonwealth‚Äôs German and Italian ethnic heritage,‚Äù and ‚ÄúTitles that cover World War I and the Spanish influenza epidemic.‚Äù<a id="fnref:20" class="footnote" title="see footnote" href="#fn:20">[20]</a></p> <p>Over their three rounds of funding, then, Penn State sought to digitize newspapers from as many counties as possible, meaning they prioritized breadth of geographic coverage over digitizing the ‚Äúmost influential‚Äù newspapers in the state, which might have produced a corpus skewed in another way: toward Philadelphia over more rural areas in the state.</p> <p>Phase II‚Äôs blog includes <a href="http://www.personal.psu.edu/kkm111/blogs/padnp2/graphs.html" target="_blank" rel="noopener noreferrer">a graph</a> and <a href="http://www.personal.psu.edu/kkm111/blogs/padnp2/maps.html" target="_blank" rel="noopener noreferrer">map</a> outlining the state of newspaper digitization in Pennsylvania at the time of that work.</p> <p><a href="/img/Map_Free-Paid-Digitized-Newspaper-Coverage-in-PA-by-County-958.jpg" target="_blank"><img src="/img/Map_Free-Paid-Digitized-Newspaper-Coverage-in-PA-by-County-958.jpg" alt="Map of historical newspaper digitization for Pennsylvania as of 2010, prepared for the Pennsylvania Digital Newspaper Program." width="600"></a></p> <p><em>Map of historical newspaper digitization for Pennsylvania as of 2010, prepared for the Pennsylvania Digital Newspaper Program.</em></p> <p>The <em>Lewisburg Chronicle, and the West Branch Farmer</em> was scanned in Phase II because Union County had been ignored by previous efforts, both public and commercial. Reading the narrative about the <em>Lewisburg Chronicle</em>, prepared for the PaNDP and now provided on CA, we understand that the paper was chosen among those published in Union Country because of its stability, as ‚ÄúAt least eight early Lewisburg weeklies came and went between 1824 and 1842‚Äù before the <em>Chronicle</em> brought a regular publication to the county.<a id="fnref:21" class="footnote" title="see footnote" href="#fn:21">[21]</a></p> <p>I cite these details neither to defend nor deride the choices made by PaDNP. Given finite time and resources, any mass digitization effort must privilege certain features from all possible corpora over others. But understanding these choices is essential for researchers building arguments, computational or otherwise, from CA or its subsidiary archives. An understanding of the corpus‚Äôs outlines and the technical composition of its materials allows us to qualify the claims we make using CA while benefiting from the remarkable possibilities of access, comparison, or analytical scale enabled by digitization. Beginning from the specific example of the <em>Lewisburg Weekly</em> helps illustrate how the constitution and provenance of digitized archives are, to some extent at least, knowable and describable. Just as details of type, ink, or paper‚Äîor paratext such as printer‚Äôs records‚Äîcan help us establish the histories under which a printed book was created, details of format, interface, and even grant proposals can help us establish the histories of corpora created under conditions of mass digitization.</p> <p>Acknowledging digitized historical texts as new editions is an important step, I would argue, to developing media-specific approaches to the digital that more effectively exploit its affordances; more responsibly represent the material, social, and economic circumstances of its production; and more carefully delineate with its limitations. To put it more bluntly, I worry that when we treat the digitized object primarily as a surrogate for its analog original, we jettison the best features of both modes. Few researchers have remediated their methodologies toward the digital archive‚Äôs unique affordances for pattern detection across vast fields. We largely haven‚Äôt learned how to ask pressing humanities questions best answered through computational means. That, I would argue, is the primary challenge facing media historians in our moment‚Äînot a technical challenge, but a challenge of imagination.</p> <div class="footnotes"> <hr> <ol> <li id="fn:1">Matthew Kirschenbaum, ‚ÄúText Messaging,‚Äù in <em>Mechanisms: New Media and the Forensic Imagination</em> (Cambridge, MA: MIT Press, 2008). <a class="reversefootnote" title="return to article" href="#fnref:1">¬†‚Ü©</a> </li> <li id="fn:2">Bonnie Mak, ‚ÄúArchaeology of a Digitization,‚Äù <em>Journal of the Association for Information Science and Technology</em> 65. 8 (August 2014): 1515. <a class="reversefootnote" title="return to article" href="#fnref:2">¬†‚Ü©</a> </li> <li id="fn:3">W. W. Greg, ‚ÄúBibliography‚Äîan Apologia,‚Äù in <em>Collected Papers</em>, ed. J. C. Maxwell (Oxford: Clarendon Press, 1966), 257, 259. <a class="reversefootnote" title="return to article" href="#fnref:3">¬†‚Ü©</a> </li> <li id="fn:4">Juxta Commons, <a href="http://juxtacommons.org/" target="_blank" rel="noopener noreferrer">http://juxtacommons.org/</a> <a class="reversefootnote" title="return to article" href="#fnref:4">¬†‚Ü©</a> </li> <li id="fn:5">McDonough, Jerome, Matthew Kirschenbaum, Doug Reside, Neil Fraistat, and Dennis Jerz; ‚ÄúTwisty Little Passages Almost All Alike: Applying the FRBR Model to a Classic Computer Game‚Äù; <em>Digital Humanities Quarterly</em> 4. 2 (2010), <a href="http://www.digitalhumanities.org/dhq/vol/4/2/000089/000089.html" target="_blank" rel="noopener noreferrer">http://www.digitalhumanities.org/dhq/vol/4/2/000089/000089.html</a> <a class="reversefootnote" title="return to article" href="#fnref:5">¬†‚Ü©</a> </li> <li id="fn:6">Terry Belanger, ‚ÄúDescriptive Bibliography,‚Äù in <em>Book Collecting: A Modern Guide</em>, ed. Jean Peters (New York: R. R. Bowker, 1977), 97. <a class="reversefootnote" title="return to article" href="#fnref:6">¬†‚Ü©</a> </li> <li id="fn:7">Johannes Trithemius, <em>In Praise of Scribes</em>, ed. Klaus Arnold, trans. Roland Behrent (Lawrence, KS: Coronado Press, 1974), 65. <a class="reversefootnote" title="return to article" href="#fnref:7">¬†‚Ü©</a> </li> <li id="fn:8">Alan Liu, ‚ÄúImagining the New Media Encounter,‚Äù in <em>A Companion to Digital Literary Studies</em>, ed. Susan Schreibman and Ray Siemens (Oxford: Blackwell, 2008), <a href="http://www.digitalhumanities.org/companion/view?docId=blackwell/9781405148641/9781405148641.xml&amp;chunk.id=ss1-3-1" target="_blank" rel="noopener noreferrer">http://www.digitalhumanities.org/companion/view?docId=blackwell/9781405148641/9781405148641.xml&amp;chunk.id=ss1‚Äì3‚Äì1</a> <a class="reversefootnote" title="return to article" href="#fnref:8">¬†‚Ü©</a> </li> <li id="fn:9">The body of OCR research is too broad to succinctly cite here, but the main conference in the field is ICDAR (International Conference on Document Analysis and Recognition), <a href="http://2015.icdar.org/" target="_blank" rel="noopener noreferrer">http://2015.icdar.org/</a>, with relevant work often presented‚Äîand collected in the conference proceedings of‚ÄîCVPR (Computer Vision and Pattern Recognition), EMNLP (Empirical Methods in Natural Language Processing), SIGIR (Special Interest Group in Information Retrieval), and NIPS (Neural Information Processing Systems). To cite only a few papers that focus on OCR of historical texts, interested readers might see Garrette et al, ‚ÄúUnsupervised Code-Switching for Multilingual Historical Document Transcription,‚Äù NAACL 2015, <a href="http://www.aclweb.org/anthology/N/N15/N15-1109.pdf" target="_blank" rel="noopener noreferrer">http://www.aclweb.org/anthology/N/N15/N15‚Äì1109.pdf</a>; Lund et al, ‚ÄúHow Well Does Multiple OCR Error Correction Generalize?‚Äù DRR 2014, <a href="http://www.researchgate.net/publication/260084914_How_Well_Does_Multiple_OCR_Error_Correction_Generalize" target="_blank" rel="noopener noreferrer">http://www.researchgate.net/publication/260084914_How_Well_Does_Multiple_OCR_Error_Correction_Generalize</a>; or Breuer et al, "High-Performance OCR for printed English and Fraktur using LSTM networks,‚Äù ICDAR 2013, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.433.4006&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener noreferrer">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.433.4006&amp;rep=rep1&amp;type=pdf</a>. <a class="reversefootnote" title="return to article" href="#fnref:9">¬†‚Ü©</a> </li> <li id="fn:10"> <a href="http://chroniclingamerica.loc.gov/awardees/pst/" target="_blank" rel="noopener noreferrer">http://chroniclingamerica.loc.gov/awardees/pst/</a> and <a href="http://chroniclingamerica.loc.gov/batches/batch_pst_fenske_ver02/" target="_blank" rel="noopener noreferrer">http://chroniclingamerica.loc.gov/batches/batch_pst_fenske_ver02/</a>. <a class="reversefootnote" title="return to article" href="#fnref:10">¬†‚Ü©</a> </li> <li id="fn:11">Exiftool, Phil Harvey, <a href="http://www.sno.phy.queensu.ca/~phil/exiftool/" target="_blank" rel="noopener noreferrer">http://www.sno.phy.queensu.ca/~phil/exiftool/</a>, downloaded 10 December 2015. <a class="reversefootnote" title="return to article" href="#fnref:11">¬†‚Ü©</a> </li> <li id="fn:12">CA‚Äôs technical guidelines have shifted over time, but scholars can access each version, depending on the date their issue of interest was digitized: * Technical Guidelines for 2007 and 2008 Awards, <a href="http://www.loc.gov/ndnp/guidelines/archive/techspecs0708.html" target="_blank" rel="noopener noreferrer">http://www.loc.gov/ndnp/guidelines/archive/techspecs0708.html</a> * Technical Guidelines for 2009 and 2010 Awards, <a href="http://www.loc.gov/ndnp/guidelines/archive/techspecs09.html" target="_blank" rel="noopener noreferrer">http://www.loc.gov/ndnp/guidelines/archive/techspecs09.html</a> * Technical Guidelines for 2012 Awards, <a href="http://www.loc.gov/ndnp/guidelines/archive/guidelines1213.html" target="_blank" rel="noopener noreferrer">http://www.loc.gov/ndnp/guidelines/archive/guidelines1213.html</a> <a class="reversefootnote" title="return to article" href="#fnref:12">¬†‚Ü©</a> </li> <li id="fn:13">The Eclipse 300 Microfilm Scanner was released by nextScan in 2009, <a href="http://www.nextscan.com/nextscan-introduces-the-eclipse-plus-high-production-rollfilm-scanner-with-lumintec-light-line-illumination-system/#.VRF8DVxCNFI" target="_blank" rel="noopener noreferrer">http://www.nextscan.com/nextscan-introduces-the-eclipse-plus-high-production-rollfilm-scanner-with-lumintec-light-line-illumination-system/#.VRF8DVxCNFI</a>. <a class="reversefootnote" title="return to article" href="#fnref:13">¬†‚Ü©</a> </li> <li id="fn:14">XML is a markup language, like the more familiar HTML (HyperText markup Language) that underlies most webpages. XML‚Äôs primary use is to storing data in a format that is both human- and machine-readable. The most familiar version XML in the humanities is the TEI, or Text Encoding Initiative, which is a group ‚Äúwhose mission is to develop and maintain guidelines for the digital encoding of literary and linguistic texts.‚Äù ‚ÄúAbout the TEI,‚Äù <a href="http://www.tei-c.org/About/" target="_blank" rel="noopener noreferrer">http://www.tei-c.org/About/</a>. <a class="reversefootnote" title="return to article" href="#fnref:14">¬†‚Ü©</a> </li> <li id="fn:15">Because Abbyy Finereader is a commercial product, the software that predicts its accuracy is not freely available for inspection. As such, we should not make too much of the figure presented here, which certainly does not align with a human reader‚Äôs assessment of the page‚Äôs overall similarity to the words on the page images. <a class="reversefootnote" title="return to article" href="#fnref:15">¬†‚Ü©</a> </li> <li id="fn:16">In October of 2010 iArchives was acquired by Ancestry.com (<a href="http://Ancestry.com" target="_blank" rel="noopener noreferrer">http://Ancestry.com</a>), and their technologies essentially became the for-profit Newspapers.com (<a href="http://Newspapers.com" target="_blank" rel="noopener noreferrer">http://Newspapers.com</a>) that feeds many of the results you get when searching family trees in Ancestry. <a class="reversefootnote" title="return to article" href="#fnref:16">¬†‚Ü©</a> </li> <li id="fn:17">Ian Milligan, ‚ÄúIllusionary Order: Online Databases, Optical Character Recognition, and Canadian History, 1997‚Äì2010,‚Äù <em>Canadian Historical Review</em> 94.4 (December 2013): 550, 567. <a class="reversefootnote" title="return to article" href="#fnref:17">¬†‚Ü©</a> </li> <li id="fn:18">Jamie Mears, <em>National Digital Newspaper Program Impact Study 2004‚Äì2014</em>, National Endowment for the Humanities (September 2014), <a href="https://www.loc.gov/ndnp/guidelines/docs/ndnp_report_2014_0.pdf" target="_blank" rel="noopener noreferrer">https://www.loc.gov/ndnp/guidelines/docs/ndnp_report_2014_0.pdf</a>. <a class="reversefootnote" title="return to article" href="#fnref:18">¬†‚Ü©</a> </li> <li id="fn:19">An overview of the PaDNP‚Äôs three phases can be found at <a href="https://www.libraries.psu.edu/psul/digipres/panp/padnp.html" target="_blank" rel="noopener noreferrer">https://www.libraries.psu.edu/psul/digipres/panp/padnp.html</a>, while production blogs for Phase I and Phase II can be found at <a href="http://www.personal.psu.edu/kkm111/blogs/pa_digital_newspaper_project/" target="_blank" rel="noopener noreferrer">http://www.personal.psu.edu/kkm111/blogs/pa_digital_newspaper_project/</a> and <a href="http://www.personal.psu.edu/kkm111/blogs/padnp2/" target="_blank" rel="noopener noreferrer">http://www.personal.psu.edu/kkm111/blogs/padnp2/</a>, respectively. As a side note, I would express some hope that Penn State University Libraries will take care to preserve these resources, which are valuable bibliographic assets for researchers using the CA corpus. <a class="reversefootnote" title="return to article" href="#fnref:19">¬†‚Ü©</a> </li> <li id="fn:20">All figures taken from <a href="https://www.libraries.psu.edu/psul/digipres/panp/padnp.html" target="_blank" rel="noopener noreferrer">https://www.libraries.psu.edu/psul/digipres/panp/padnp.html</a>. <a class="reversefootnote" title="return to article" href="#fnref:20">¬†‚Ü©</a> </li> <li id="fn:21">This narrative can be found at <a href="http://chroniclingamerica.loc.gov/lccn/sn85055199/" target="_blank" rel="noopener noreferrer">http://chroniclingamerica.loc.gov/lccn/sn85055199/</a>. <a class="reversefootnote" title="return to article" href="#fnref:21">¬†‚Ü©</a> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>