<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>A Larger View of Digital American Studies | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/a-larger-view-of-digital-american-studies/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Larger View of Digital American Studies</h1> <p class="post-meta">January 23, 2017</p> <p class="post-tags"> <a href="/blog/2017"> <i class="fas fa-calendar fa-sm"></i> 2017 </a> </p> </header> <article class="post-content"> <p>The following is a short response article that will appear in <a href="http://dgfa.de/american-studiamerican-studies-a-quarterly-2about-american-studies-a-quarterly/" target="_blank" rel="noopener noreferrer"><em>Amerikastudien/American Studies</em></a> 61.3 (2016). Thanks to their very generous copyright policy (in brief: authors keep rights) I am glad to share the piece here as well. Obviously I cannot reproduce Alex Dunst‚Äôs article, to which I am responding, on my personal research blog, but hopefully my general points of agreement and divergence will be clear enough to readers without access to <em>Amerikastudien/American Studies</em>. With limited space I could not be as capacious as I might otherwise be describing intriguing current research in digital American Studies. I restricted myself to more computational work not because I see it as constituting the boundaries of the field‚Äîas I hope this piece does make very clear‚Äîbut instead to show that even within the subfields of computational text and image analysis we are seeing projects bloom that defy any dichotomy‚Äîoffered in praise or condemnation‚Äîbetween empirical or theoretical analyses. Side note: for this journal I had to use in MLA style, which I haven‚Äôt done in awhile and <a href="http://www.theonion.com/article/4-copy-editors-killed-in-ongoing-ap-style-chicago--30806" target="_blank" rel="noopener noreferrer">feel weird about</a>.</p> <hr> <blockquote> <p>By abandoning our conception of the computer as merely a mechanical clerk suited mostly to repetitive routine operations, by learning to know its features, uses, limitations, and possibilities‚Äîits nature, in short‚Äîwe shall be properly re-organizing our thinking for the new age. What the computer will enable us to do in our humanistic tasks has hardly been imagined yet. Even immoderate speculation tends to fall behind the new reality.</p> <p>Louis T. Milic, ‚ÄúThe Next Step‚Äù (1966)</p> </blockquote> <p>The digital humanities are large; they contain multitudes: a rewriting of Whitman that can read equally as commendation or condemnation. To cite a specific example, it might surprise that scholars who devote their work to the textually minute processes of editing and encoding digital scholarly editions rightly consider themselves members of the same field as scholars who develop algorithms for classifying data across millions of works. Yet both of these things are digital humanities (DH).</p> <p>The most commonly cited genealogy of the DH field‚Äîboth in the popular press and in scholarship, such as Dunst‚Äôs ‚ÄúDigital American Studies‚Äù article in this issue‚Äîbegins with Father Roberto Busa‚Äôs indexes and moves through Humanities Computing, following an inexorable path toward Franco Moretti, distant reading, and macroanalysis. This chronology conflates ‚Äúdigital humanities‚Äù with particular kinds of DH research that happen largely in literary studies, leaving digital history, archeology, classics, art history, religious studies, and the many other fields that contribute to DH out of the narrative. Such genealogies also overlook conversations happening with the DH community about its diverse genealogies. As Adeline Koh argues,</p> <blockquote> <p>We need to cast our formulation of the history of the digital humanities beyond the field of humanities computing to incorporate into its intellectual genealogy such fields as new media studies, diy (do-it-yourself) digital recovery projects from the 1990s, digital projects on postcolonial studies, and work taking place outside of the provenance of the United States and the United Kingdom.</p> </blockquote> <p>Koh further proposes that these histories should include also ‚Äúpostcolonial and feminist science and technology studies [‚Ä¶] work on Afrofuturism and ‚Äúand other varied scholarship on race and the Internet‚Äù (102). Other scholars have argued forcefully for histories of DH that locate its genealogies in design or multimodal composition. Meanwhile, Tom Scheinfeldt writes digital public history as ‚Äúa story that begins with people like Allan Nevins of the Columbia Oral History Office and Alan Lomax of the Library of Congress‚Äôs Archive of American Folk-Song, especially with the man on the street interviews Lomax coordinated in the aftermath of the Pearl Harbor attacks.‚Äù Such revised genealogies of the field offer important historical and theoretical contexts for DH research and teaching in the present moment, and in particular promise a more robust foundation for digital American Studies. Any genealogy of DH and American Studies must note that #transformDH, a movement envisioning ‚Äúa digital humanities that will center on the intersection of digital production and social transformation through research, pedagogy, and activism,‚Äù coalesced at the American Studies Association conference in 2011 (Bailey et al).</p> <p>Considering other origin stories for DH also helps us avoid conflating ‚Äúbig data‚Äù or ‚Äúdistant reading‚Äù with the field entire, or of positing corpus-level text analysis as the primary activity of the field rather than one activity of the field. Such a view risks excluding DH research in encoding, archive building, mapping, sound studies, and digital publication, to name only a few branches of DH less prominently featured in journalistic or scholarly rumination on the field. My own DH research began encoding digital scholarly editions and drifted toward computational text analysis, a shift accompanied by a growing awareness of how frequently the latter is taken as a metonymy for the field. In the remainder of these brief remarks, I too will focus on computational text analysis, but with the aim of offering a more nuanced view of its role in the DH field and its potential within American Studies.</p> <p>When computational text analysis is taken as the center of DH, its primary intervention is often framed as introducing empiricism into humanistic disciplines, allowing hypotheses to be offered and then either validated or falsified. Dunst summarizes this view, ‚ÄúFor the first time, quantitative but also other empirical approaches allow for transparent validation or falsification, based on representative corpora and established tools that can be disclosed and shared‚Ä¶the results of empirical testing are better described as findings: what DH scholars initially observe are statistical patterns that must be explained to produce insights.‚Äù Certainly some scholars claim, explicitly or implicitly, that computation enables a new relationship to evidence and proof for humanities scholars. Consider Moretti‚Äôs praise of ‚Äúoperationalizing,‚Äù which in his account</p> <blockquote> <p>describes the process whereby concepts are transformed into a series of operations‚Äîwhich, in their turn, allow to measure all sorts of objects. Operationalizing means building a bridge from concepts to measurement, and then to the world. In our case: from the concepts of literary theory, through some form of quantiÔ¨Åcation, to literary texts.</p> </blockquote> <p>For Moretti, this principle of operationalizing helps demonstrate ‚Äúhow the unprecedented empirical power of digital tools and archives oÔ¨Äers a unique chance to rethink the categories of literary study‚Äù (1, 13). A similar impulse could be traced in David L. Hoover‚Äôs claim that ‚ÄúLiterary criticism‚Äôs problematic relationship to facts, claims, and evidence seems more like a bug than a feature,‚Äù and his work to identify a subset of literary questions that are ‚Äútractable,‚Äù ‚Äútestable,‚Äù and ‚Äúsolvable‚Äù using computational methods (online). We might also consider Matthew L. Jockers‚Äô recent posts about his Syuzhet Package for the R programming language, which attempts to be a ‚Äúsystematic way of extracting plot arcs from fiction.‚Äù This software and Jockers‚Äô use of it to extract ‚Äúsix, or possibly seven, archetypal plot shapes‚Äù led to a heated debate among computational humanities scholars about technical topics such as Fourier transformations and low pass filters.<sup id="fnref:Jockers" role="doc-noteref"><a href="#fn:Jockers" class="footnote" rel="footnote">1</a></sup></p> <p>I cite these examples not to vilify these scholars or their work. By positing that humanistic questions might advance through hypotheses, testing, and validation, such research offers provocations for humanists resting perhaps too comfortably on implicit ideas about the boundaries of inquiry in their fields. Whether such work represents true empiricism or some kind of positivist scientism depends on whose account one trusts. As Stephen Ramsay notes, ‚ÄúThere are many who think scatter plots filled with data points drawn from, say, English novels, are already a crime against the humanities [‚Ä¶.] For them, the problem is positivism in its properly technical sense. They fear an epistemology that does not merely value empirical data, but which (in its extreme philosophical forms) considers empirical data to be the only valid form of evidence.‚Äù With Ramsay, I would argue ‚Äúthese fears are not so much unwarranted as they are grossly overblown‚Äù (‚ÄúHumane‚Äù).</p> <p>The most vital critical voices in digital humanities today‚Äîand even within the subfield of computational text analysis‚Äîresist binary accounts of computation or its potential for humanistic research and promise to enliven theories of Digital American Studies. In a recent conference paper, Lauren Klein offers a compelling metaphor for an experimental, humanistic, even ludic mode of computational research that draws on the unique affordances of the digital medium without falling into a trap of scientism. Klein describes topic modeling‚Äîa statistical technique for identifying closely-associated words within a corpus‚Äîas ‚Äúa technique that stirs the archive,‚Äù bringing unexpected patterns and connections into view. Klein reminds us that ‚Äúfor the model to be truly meaningful, domain experts [‚Ä¶] must be able to probe the semantic associations that the model proposes, and seek out additional perspectives on the model, as well as on the archive itself‚Äù (‚ÄúCarework‚Äù).</p> <p>Computational methods can reorganize the archive in new and multiple ways, offering humanists novel perspectives on its contents and their relationships. ‚ÄúBig data‚Äù is not a product of digitization, though digitization perhaps makes the vastness of the archive more apparent. Digitization can enable scholars to sift through the archive differently than we have in the past, to surface features of which we were unaware, or to test ideas across wider sections of primary texts. In ‚ÄúThe Image of Absence: Archival Silence, Data Visualization, and James Hemings,‚Äù Klein models such an approach, using network visualizations drawn from the Papers of Thomas Jefferson to read against the erasures of that same archive. By visualizing Jefferson‚Äôs many close connections to enslaved people he mentions but does not name in his letters, Klein ‚Äúconjures a sense of the dependence, on the part of Jefferson, on the men and women he enslaved, even as it cannot recreate what these people said in their conversations, where they went in order to conduct their transactions, and how they truly lived their everyday lives‚Äù (673-74). Klein‚Äôs research moves actively between patterns across her corpus and close textual details, while her computational work pressures rather than reifies the biases of her source archive. We can note a similar impulse in mapping projects such as the multi-institutional project <a href="https://dsl.richmond.edu/panorama/redlining/" target="_blank" rel="noopener noreferrer">‚ÄúMapping Inequality: Redlining in New Deal America,‚Äù</a> which uses ‚Äúsecurity maps,‚Äù produced by the Home Owners‚Äô Loan Corporation between 1935-1940, to illustrate the ways ‚Äúfederal housing programs helped codify and expand practices of racial and class segregation‚Äù in the United States (Mapping).</p> <p>Another way in which computational tools stir the archive is by aiding scholars who wish to reconstruct earlier material phenomena that leave traces, often quite subtle, in their digitized forms. The <a href="http://photogrammar.yale.edu/" target="_blank" rel="noopener noreferrer">Photogrammar project at Yale University</a>, for instance, offers a range of novel methods for organizing, searching, and visualizing the ‚Äú170,000 photographs from 1935 to 1945 created by the United States Farm Security Administration and Office of War Information‚Äù (Wexler). Photogrammar reimagines this photography archive in a number of generative ways, such as by mapping the locations of photographs, allowing scholars to imagine the collection spatially. A forthcoming interface will enable exploration based on similarities of hue, saturation, and lightness across the photographs: an aesthetic mode of interaction that draws from art and design rather than the typical hierarchies of catalogs but which is made possible by computational image analysis. Perhaps the most surprising insight of the Photogrammar project is their discovery that buried in the Library of Congress‚Äô MARC records for the FSA-OWI photographs were sequences of letters and numbers that referred back to each photograph‚Äôs place in an original roll of film. Using these features, the Photogrammar researchers can <a href="http://photogrammar.yale.edu/blog/index970c.html?p=25" target="_blank" rel="noopener noreferrer">computationally reconstruct the order in which strips of film were shot</a> by FSA-OWI photographers in the 1930s and 40s (Tilton).</p> <p>My own research with the <a href="http://viraltexts.org" target="_blank" rel="noopener noreferrer">Viral Texts project</a> adopts an exploratory method of ‚Äúbottom-up bibliography,‚Äù beginning from computational observations of text reuse in order to reconstruct bibliographies of popular nineteenth century newspaper literature.<sup id="fnref:VT" role="doc-noteref"><a href="#fn:VT" class="footnote" rel="footnote">2</a></sup> Our work operationalizes the question of reprinting, using the pattern-finding capabilities of the computer to identify groups of text strings‚Äîwhat computer scientists would call Ngrams, or sequences of words of N length‚Äîthat closely align with other groups of text strings across our source archives. We seek to redress one of the key limitations of keyword search: that it only surfaces patterns scholars are already primed to look for and thus merely amplifies our presuppositions rather than challenging them. Keyword search can help scholars find copies of texts they know to search for‚Äîin other words, familiar, canonical works‚Äîbut it cannot make inferences about widely reprinted texts lost to scholarly bibliographies. By attending to a formal feature of the digitized archive‚Äîoverlapping strings of words that appear near each other in multiple newspaper issues‚Äîwe identify reprints irregardless of topic, author, or genre, including previously unknown but popular texts and those that do not explicitly identify themselves as reprints. The aim of such modeling is to ‚Äústir the archive‚Äù of nineteenth-century newspapers and surface widely circulated and read texts that shaped nineteenth-century cultural conversations but escaped the slower processes of canon formation. For instance, the poems surfaced by Viral Texts are most often anonymous, or penned by authors virtually unknown in anthologies of the period.<sup id="fnref:FugitivePoems" role="doc-noteref"><a href="#fn:FugitivePoems" class="footnote" rel="footnote">3</a></sup> Moreover, in our data these poems intermix with an incredible variety of popular writing scholars rarely address: e.g. recipes, advice columns, jokes, popular science, even listicles. The point of this work is not to construct a definitive, empirical solution to the problem of nineteenth-century newspaper reprinting, but to facilitate an iterative conversation between the large-scale, quantitative output generated by a corpus analysis algorithm and qualitative, literary-historical readings of the surprising texts that algorithm brings into focus.</p> <p>Indeed, the most vital computational work both stirs the archive and interrogates the structures of computation, using seeming exceptions, mistakes, or false positives in the ‚Äúcodework‚Äù as intellectual pivots toward unexpected new insight. In Hoyt Long and Richard Jean So‚Äôs computational exploration of modernist haiku poetry, for example, their algorithm identified a small but significant number of poems as haiku that they, as domain experts, would not classify as such. Rather than simply dismiss these false positives, however, Long and So engage these anomalies critically and historically, asking what features they do share with haiku that led to their misclassification, and identifying the subtle, diffuse influence of an Orientalist poetic style across the work of a range of modernist poets. As Long and So argue, humanistic computational work ‚Äúwill require a method of reading that oscillates or pivots between human and machine interpretation, each providing feedback to the other in the critic‚Äôs effort to extract meaning from texts. Literary pattern recognition, then, brings together close reading, cultural history, and machine learning so that they supplement one another‚Äù (266-267). Here rigid operations of the algorithm reorganizes texts across the genre boundaries established by previous scholarship, pressuring conventional readings of individual poems but also exposing the logic of computational categorization. A seeming glitch in the software generates humanistic insight.</p> <p>I join Dunst‚Äôs final exhortation for humanists‚Äîand Americanists in particular‚Äîto view computation as a cultural <em>and</em> technical domain that requires our participation. My understanding of the line between ‚Äúhumanistic argument and computational logic,‚Äù however, is less polarized than Marche‚Äôs or Hall‚Äôs (with whom Dunst ends his article). To begin, our colleagues in computer science and related disciplines are more interested in complex data and hard, theoretical questions than we typically countenance. Corporate computing is ubiquitous in daily life, but does not describe the boundaries of computer science research, which often seeks precisely challenges that seem intractable, such as those rooted in language. As computation waxes both politically and sociologically, we need genuine, interdisciplinary conversation and, dare I say, intellectual exchange between our fields.<sup id="fnref:CS" role="doc-noteref"><a href="#fn:CS" class="footnote" rel="footnote">4</a></sup> Next, the long history of media makes clear that narratives of new media replacement rarely capture the nuances of real historical change. As Alan Liu reminds us, ‚Äúnew media encounters are messy,‚Äù meaning ‚Äúthat right-angled historical, socio-political, or psychological distinctions between old and new media typically do not survive concrete acts of narration. Instead, binary distinctions open out into overlapping, contradictory, or otherwise thick affordances between media regimes‚Äù (online). Both apocalyptic pronouncements and millennialist announcements likely miss the reality of our new scholarly ecology, which can foster both ingenious computational-humanistic praxis and rich critique of digital culture. We find ourselves in a ‚Äúthick, unpredictable zone of contact‚Äîmore borderland than border line‚Äù between computation and humanistic inquiry (Liu). Through creative, theoretically-informed engagements with and through the digital, American Studies can help shape the narrative of our new media rather than being reshaped from outside. Like DH, a digitally-informed American Studies must be large; it must contain multitudes, if it is to thrive in the twenty-first century.</p> <hr> <h2 id="works-cited">Works Cited</h2> <p>Bailey, Moya, Anne Cong-Huyen, Alexis Lothian, and Amanda Phillips. ‚ÄúReflections on a Movement: #transformDH, Growing Up.‚Äù <em>Debates in the Digital Humanities</em> 2016. Minneapolis: U of Minnesota P, 2016. Web. <a href="http://dhdebates.gc.cuny.edu/debates/text/59" target="_blank" rel="noopener noreferrer">http://dhdebates.gc.cuny.edu/debates/text/59</a>.</p> <p>Hoover, David L. ‚ÄúArgument, Evidence, and the Limits of Digital Literary Studies.‚Äù <em>Debates in the Digital Humanities</em> 2016. Minneapolis: U of Minnesota P, 2016. 230-50. Print. Also available online at <a href="http://dhdebates.gc.cuny.edu/debates/text/71" target="_blank" rel="noopener noreferrer">http://dhdebates.gc.cuny.edu/debates/text/71</a>.</p> <p>Jockers, Matthew L. ‚ÄúThe Rest of the Story‚Äù (25 February 2015). Web. <a href="http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story" target="_blank" rel="noopener noreferrer">http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/</a>.</p> <p>Klein, Lauren. ‚ÄúThe Carework and Codework of the Digital Humanities,‚Äù Digital Antiquarian Conference Talk, May 2015, <a href="http://lklein.com/2015/06/the-carework-and-codework-of-the-digital-humanities/" target="_blank" rel="noopener noreferrer">http://lklein.com/2015/06/the-carework-and-codework-of-the-digital-humanities/</a>.</p> <p>‚Äî‚Äî. ‚ÄúThe Image of Absence: Archival Silence, Data Visualization, and James Hemings,‚Äù <em>American Literature</em> 85.4 (2013): 661-88. Print.</p> <p>Koh, Adeline. ‚ÄúNiceness, Building, and Opening the Genealogy of the Digital Humanities: Beyond the Social Contract of Humanities Computing.‚Äù 93-106. <em>differences</em> 25.1 (2014). Print.</p> <p>Liu, Alan. ‚ÄúImaging the New Media Encounter.‚Äù <em>A Companion to Digital Literary Studies</em>. Eds. Susan Schreibman and Ray Siemens. Oxford: Blackwell, 2008. Print. Also available online at <a href="http://www.digitalhumanities.org/companion/view?docId=blackwell/9781405148641/9781405148641.xml&amp;chunk.id=ss1-3-1&amp;toc.depth=1&amp;toc.id=ss1-3-1&amp;brand=9781405148641_brand" target="_blank" rel="noopener noreferrer">http://www.digitalhumanities.org/companion/view?docId=blackwell/9781405148641/9781405148641.xml&amp;chunk.id=ss1-3-1&amp;toc.depth=1&amp;toc.id=ss1-3-1&amp;brand=9781405148641_brand</a>.</p> <p>Long, Hoyt, and Richard Jean So. ‚ÄúLiterary Pattern Recognition: Modernism between Close Reading and Machine Learning:‚Äù <em>Critical Inquiry</em> 42 (2016): 235-67. Print.</p> <p>Mapping Inequality: Redlining in New Deal America. Web. https://dsl.richmond.edu/panorama/redlining/.</p> <p>Milic, Louis T. ‚ÄúThe Next Step,‚Äù <em>Computers and the Humanities</em> 1.1 (1966): 3-6. Print.</p> <p>Moretti, Franco. ‚Äú‚ÄòOperationalizing‚Äô: or, the Function of Measurement in Modern Literary Theory.‚Äù Stanford Literary Lab Pamphlet 6 (2013). Web. <a href="https://litlab.stanford.edu/LiteraryLabPamphlet6.pdf" target="_blank" rel="noopener noreferrer">https://litlab.stanford.edu/LiteraryLabPamphlet6.pdf</a>.</p> <p>Stephen Ramsay. ‚ÄúHumane Computation.‚Äù <em>Debates in the Digital Humanities</em> 2016. Minneapolis: U of Minnesota P, 2016. 527-29. Print. Also available online at <a href="http://dhdebates.gc.cuny.edu/debates/text/94" target="_blank" rel="noopener noreferrer">http://dhdebates.gc.cuny.edu/debates/text/94</a>.</p> <p>Scheinfeldt, Tom. ‚ÄúThe Dividends of Difference: Recognizing Digital Humanities‚Äô Diverse Family Tree/s.‚Äù Found History (2014). Web. <a href="http://foundhistory.org/2014/04/the-dividends-of-difference-recognizing-digital-humanities-diverse-family-trees/" target="_blank" rel="noopener noreferrer">http://foundhistory.org/2014/04/the-dividends-of-difference-recognizing-digital-humanities-diverse-family-trees/</a>.</p> <p>Tilton, Lauren. ‚ÄúStrips.‚Äù Photogrammar research blog (6 November 2013). Web. <a href="http://photogrammar.yale.edu/blog/index970c.html?p=25" target="_blank" rel="noopener noreferrer">http://photogrammar.yale.edu/blog/index970c.html?p=25</a>.</p> <p>Wexler, Laura, et al. Photogrammar. Web. <a href="http://photogrammar.yale.edu/" target="_blank" rel="noopener noreferrer">http://photogrammar.yale.edu/</a>.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:Jockers" role="doc-endnote"> <p>The debate over Syuzhet unfolded largely through research blogs and social media and thus is difficult to cite as an event. My quotation comes from Matthew L. Jockers, ‚ÄúThe Rest of the Story‚Äù (25 February 2015), <a href="http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/" target="_blank" rel="noopener noreferrer">http://www.matthewjockers.net/2015/02/25/the-rest-of-the-story/</a>. Fortunately, Eileen Clancy compiled a Storify that usefully outlines the larger discussion of which this post is only one part. That Storify can be found at <a href="https://storify.com/clancynewyork/contretemps-a-syuzhet" target="_blank" rel="noopener noreferrer">https://storify.com/clancynewyork/contretemps-a-syuzhet</a>.¬†<a href="#fnref:Jockers" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:VT" role="doc-endnote"> <p>For more about the Viral Texts Project, including project data and publications, see the research website at <a href="http://viraltexts.org" target="_blank" rel="noopener noreferrer">http://viraltexts.org</a>.¬†<a href="#fnref:VT" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:FugitivePoems" role="doc-endnote"> <p>An article about these ‚ÄúFugitive Verses‚Äù is forthcoming in American Periodicals in 2017. A preprint of that article is available at <a href="http://viraltexts.org/2016/04/08/fugitive-verses/" target="_blank" rel="noopener noreferrer">http://viraltexts.org/2016/04/08/fugitive-verses/</a>.¬†<a href="#fnref:FugitivePoems" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:CS" role="doc-endnote"> <p>In general, I suspect most humanist have very little idea what computer scientists research (and vice versa), a quandary well outlined in Stephen Ramsay‚Äôs article ‚ÄúDH and CS,‚Äù <a href="http://stephenramsay.us/2013/04/30/dh-and-cs/" target="_blank" rel="noopener noreferrer">http://stephenramsay.us/2013/04/30/dh-and-cs/</a>.¬†<a href="#fnref:CS" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>