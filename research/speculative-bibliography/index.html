<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Speculative Bibliography | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/speculative-bibliography/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Speculative Bibliography</h1> <p class="post-meta">January 10, 2020‚Ä¢ Ryan Cordell</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a> </p> </header> <article class="post-content"> <p><em>The following was presented at the MLA 2020 Convention in the panel ‚ÄúArchitextures of Knowledge,‚Äù sponsored by the Society for Textual Scholarship.</em></p> <hr> <h2 id="recurated-and-reedited">Recurated and Reedited</h2> <p>Jerome McGann begins his 2014 book, <em>A New Republic of Letters</em>, channeling an imperative he first articulated at least thirteen years earlier: ‚ÄúHere is surely a truth now universally acknowledged: that the whole of our cultural inheritance has to be recurated and reedited in digital forms and institutional structures.‚Äù McGann despairs that current digital archives are, by and large, being created by for-profit entities, using errorful automated processes such as optical character recognition (OCR), and by workers trained in the technical aspects of digitization, but not in the historical and cultural dimensions of the artifacts being digitized. What is required, McGann argues, is a sustained, collective scholarly intervention:</p> <blockquote> <p>Digitizing the archive is not about replacing it. It‚Äôs about making it usable for the present and the future. To do that we have to understand, as best we can, how it functioned‚Äîhow it made meanings‚Äîin the past. A major task lying before us‚Äîits technical difficulties are great‚Äîis to design a knowledge and information network that integrates, as seamlessly as possible, our paper-based inheritance with the emerging archive of born-digital materials (21-22)<sup id="fnref:McGann" role="doc-noteref"><a href="#fn:McGann" class="footnote" rel="footnote">1</a></sup></p> </blockquote> <p>What does it mean to make the archive ‚Äúusable for the present and the future,‚Äù and how do notions of usability change due to digitization? The massive scale and cost of the effort McGann advocates seem impossible in the current age of educational austerity‚Äîwhich is particularly felt in the humanities‚Äîand yet the imperative to design multiple paths into both ‚Äúour paper-based‚Äù and ‚Äúborn digital‚Äù inheritances seems clear.</p> <p><em>In the longer version of this paper, I do some work here to dispel the notion that scale and cost are challenges unique to the digital age, pointing out that the majority of our paper-based inheritance was never curated or edited prior to the digital age. We can discuss this claim more in the Q&amp;A if folks would like.</em> The fact is that we will not have the time and labor required to digitize all books to the standards we might wish, a task even less imaginable for materials such as newspapers, pamphlets, tracts, and periodicals. In such a reality, digital scholarly editing remains an essential endeavor, but it must proceed in parallel with other experiments that meet the mass digitized archive where it is, leverage the unique affordances of digital media to explore its contours, and identify areas of scholarly interest from a well of largely undifferentiated content.</p> <h2 id="toward-speculative-bibliography">Toward Speculative Bibliography</h2> <p>This paper proposes <em>speculative bibliography</em> as a complementary, experimental approach to the digitized archive, in which textual associations are constituted propositionally, iteratively, and (sometimes) temporarily, as the result of probabilistic computational models. A speculative bibliography enacts a scholarly theory of the text, reorganizing the archive to model a particular idea of textual relation or interaction. Many computational processes already create data we might identify as speculative bibliographies: algorithms that detect the relative prevalence of ‚Äútopics‚Äù across documents, identify sequences of duplicate text in a corpus, or more simply list texts that share search terms.</p> <p>Our work on the <em>Viral Texts</em> project at Northeastern University, for instance, uses text mining techniques to trace the reprinting of material in nineteenth-century newspapers across the globe.[^ViralTexts] To simplify things just a bit, our method posits that the editorial practice of reprinting can be modeled in this way:</p> <p>‚Äúif passages of text from separate pages contain at least five matching phrases of five-words length and their words overlap each other by at least 80%, they should be considered ‚Äòthe same‚Äô and clustered together.‚Äù</p> <p>Essentially, we have developed a textual model that is agnostic on questions of author, title, genre, or similar categories which are largely absent from either the nineteenth-century newspaper page <em>or</em> the metadata of twenty-first century digitized newspaper archives. To write that another way, it is a method that does, I believe, account how the nineteenth-century newspaper ‚Äúmade its meanings,‚Äù as well as the ways that current digital newspaper archives mask those meanings. This kind of pattern matching‚Äîidentifying overlapping strings of characters across tens of millions of newspaper pages‚Äîwould be far beyond the capabilities of a human researcher or the operational capacities of an individual archive. The project relies on digital archives that federate newspapers physically distributed around the world, which means an analog effort along these same lines would require more time than any researcher possesses, an incredibly intricate indexing system, and enormous geographic mobility. Speculative bibliography recognizes that a unique affordance of digital media is the ability to rapidly reorganize or reconfigure its contents and seeks to identify meaningful patterns for exploration within collections that are often messy and unevenly described. In the <em>Viral Texts</em> model, textual relationships are determined by the formal structures internal to the texts themselves, but our algorithm is nonetheless a bibliographic argument.</p> <h3 id="why-bibliography">Why ‚ÄúBibliography‚Äù?</h3> <p>To oversimplify just a bit, we might describe bibliography as a system for modeling textual relationships. The bibliographer decides that these texts belong together because they share certain metadata (e.g. author, genre, era of publication) while these others might belong together because they share formal material features (e.g. octavo format, dos-√†-dos binding). In many bibliographic traditions, these relationships are mapped out quite methodically and procedurally‚Äîdare I write algorithmically?‚Äîwhich is perhaps why bibliography can seem ‚Äúdry as dust‚Äù to outside observers. However, bibliographers share a conviction Jonathan Senchyne summarizes beautifully in his new book that ‚ÄúMaterial textuality means‚Ä¶the material presence of something is itself figurative and demands close reading‚Äù alongside a text‚Äôs linguistic content (6)<sup id="fnref:Senchyne" role="doc-noteref"><a href="#fn:Senchyne" class="footnote" rel="footnote">2</a></sup></p> <p>The constellation I want to gather under the sign of speculative bibliography comprises computational and probabilistic methods that map relationships among documents, that sort and organize the digital archive into related sets. I employ <em>bibliography</em> to insist that such methods belong to the textual systems they transform, and should themselves be objects of research and scrutiny, described with the same rigor that bibliographers and book historians describe historical technologies of knowledge production.</p> <p>Earlier in the digital age, Thomas Tanselle proposed a definition for what he called an ‚Äúelectronic edition‚Äù of a text:</p> <blockquote> <p>in order to include modern methods of book production which do not involve actual type setting, an edition should be defined as all copies resulting from a single job of typographical composition. Thus whether printed from type (set by hand or by machine), or plates, or by means of a photographic or electronic process, all copies that derive from the same initial act of assembling the letterforms belong to the same edition (18)<sup id="fnref:Tanselle" role="doc-noteref"><a href="#fn:Tanselle" class="footnote" rel="footnote">3</a></sup></p> </blockquote> <p>Where previous bibliographers had focused on composition as the setting of metal type (whether moveable characters of cold type or a line of hot type), Tanselle recognized that typing at a computer keyboard was also an act of inscription, committing a particular arrangement of typographic characters‚Äî‚Äùassembling the letterforms‚Äù‚Äîto memory. <a href="https://ryancordell.org/research/qijtb-the-raven/">In a recent article in <em>Book History</em></a>, I pivot from Tanselle to argue that humanities scholars need to take optical character recognition (OCR) seriously as a material and cultural artifact. OCR software scans digitized page images, attempting to recognize the letterforms on the images and transcribe them into a text file. I argue that we might consider OCR a species of compositor, setting type in a language it can see but not comprehend, and thus that OCR data derived from a historical text is a new edition‚Äîa copy ‚Äúresulting from a <em>single job of typographical composition</em>‚Äú‚Äîof that text.<sup id="fnref:OCR" role="doc-noteref"><a href="#fn:OCR" class="footnote" rel="footnote">4</a></sup> It is a kind of offset composition, in which the programmer sets the rules for recognition that the program will follow to create many editions.</p> <p>This paper expands that frame further to think about code‚Äîsuch as that underlying reprint detection or classification‚Äîas another job of typographical composition that inscribes a theory of textual relationship, at least when its objects are bibliographic or textual. That last caveat is important, because just as we wouldn‚Äôt claim all written analysis as bibliographic, we shouldn‚Äôt claim all code as bibliographic. Annette Vee points to the double valence of code when she writes that</p> <blockquote> <p>Programming has a complex relationship with writing; it <em>is</em> writing‚Ä¶because it is symbols inscribed on a surface and designed to be read. But programming is also <em>not</em> writing, or rather, it is something more than writing. The symbols that constitute computer code are designed not only to be read but also to be executed, or <em>run</em>, by the computer.</p> </blockquote> <p>Vee continues in a line that echoes (though I suspect accidentally) Tanselle, writing that ‚Äúprogramming is the authoring of processes to be carried out by the computer‚Äù (20).<sup id="fnref:Vee" role="doc-noteref"><a href="#fn:Vee" class="footnote" rel="footnote">5</a></sup> Denis Tenen argues something similar when he writes ‚ÄúUnlike figurative description, machine control languages function in the imperative. They do not stand for action; they are action‚Äù (94).<sup id="fnref:Tenen" role="doc-noteref"><a href="#fn:Tenen" class="footnote" rel="footnote">6</a></sup> A program becomes speculative bibliography when its action operationalizes a theory of textual relationship. If OCR is a species of compositor, such algorithms might be species of editor, set loose with one unwavering principle of selection apiece. Speculative bibliography is action and documentation.</p> <p>Consider a classification algorithm. <a href="https://manifold.umn.edu/read/untitled-bd3eb0af-fdad-4dd6-9c94-3fd15d522ab6/section/06899e82-8f06-43d2-9fc9-ea04dffef886" target="_blank" rel="noopener noreferrer">We use these in the <em>Viral Texts</em> project</a> to sort millions of individual reprints into generic categories: fiction, news, poetry, science writing, domestic writing, etc. Classification is typically a supervised task, in which researchers tag a set of documents‚Äîthe training dataset‚Äîas belonging to the various genres they hope to identify. From this training data, different classification algorithms can be used to compare unknown texts against known. Some classification algorithms use words to determine belongingness: e.g. domestic fiction will use words like ‚Äúeye,‚Äù ‚Äúheart,‚Äù ‚Äúmother,‚Äù or ‚Äútear‚Äù in much higher proportion than we would expect from random chance, while news articles will disproportionately use words like ‚Äúship,‚Äù ‚Äúpresident,‚Äù ‚Äúbill,‚Äù or ‚Äúdebate.‚Äù I‚Äôm making these lists up, because in reality they depend entirely on a specific research corpus and researchers‚Äô initial genre classifications, but word-based classification works roughly in this way. There are also other classification methods that use topic or vector space models to establish relationships among the words in different texts.</p> <p>I want to consider these processes as displaced forms of editing that operate with less precision but greater speed and scale than solely human endeavor: a kind of offset editing. Editors create models of textual relationship through tagging their training data and then operationalize those models across a wider textual field than they could edit alone. In our case we spend a few weeks manually tagging several hundred texts per genre in order to classify millions of unknown texts in an afternoon. Importantly, these methods are not binary, but probabilistic across all genres for which we create a training set, so that one text might be classified as 79% likely to be poetry and 65% likely to be religious. If we later seek out popular newspaper poetry or religion (or religious poetry) we would find such a text. Of course, with such a method there are many false positives or false negatives: texts that a human reader would recognize as an account of a cricket match, for instance, but that the classifier identifies as poetry, or texts that a human observer would recognize as poetry but that a classifier fails to identify as likely to be such. If such methods are bibliographic because they posit textual relationships and paths through mass digital archives, they are speculative because the paths they posit are probabilistic, experimental, and iterative.</p> <h3 id="why-speculative">Why ‚ÄúSpeculative?‚Äù</h3> <p>With speculative bibliography, I seek an intellectual frame that recognizes the practical, theoretical, and historiographical potential of exploratory computation without resorting to dehistoricized, idealized notions of ‚Äúbig data,‚Äù to negotiate a middle ground between strong theories of ‚Äúdistant reading‚Äù or ‚Äúcultural analytics‚Äù on the one hand and the ‚Äúscholarly edition of a literary system‚Äù more recently advocated by Katherine Bode. I am fully convinced by Bode‚Äôs argument that,</p> <blockquote> <p>Contrary to prevailing opinion, distant reading and close reading are not opposites. These approaches are united by a common neglect of textual scholarship: the bibliographic and editorial approaches that scholars have long depended on to negotiate the documentary record (19).<sup id="fnref:Bode" role="doc-noteref"><a href="#fn:Bode" class="footnote" rel="footnote">7</a></sup></p> </blockquote> <p>Bode rightly points out that most ‚Äúdata-rich literary history‚Äù projects fail to fully delineate ‚Äúthe broader relationship between the literature of the past and the disciplinary infrastructure used to investigate it‚Äù (52) She advocates instead for the ‚Äúscholarly edition of a literary system‚Äù in which</p> <blockquote> <p>A curated dataset replaces the curated text‚Ä¶In the form of bibliographical and textual data, it manifests‚Äîdemonstrates and, specifically, publishes‚Äîthe outcome of the sequence of production and reception, including the current moment of interpretation, described in the critical apparatus. The model it provides is stable: it is published and accessible for all to use, whether for conventional or computational literary history. But that stability does not belie or extinguish its hypothetical character. Rather than showing a literary system, it presents an argument about the existence of literary works in the past based on the editor‚Äôs interpretation of the multiple transactions by which documentary evidence of the past is transmitted for the present (53).</p> </blockquote> <p>Bode models this in the carefully-curated datasets she compiles about Australian newspaper fiction, which I would point to as an exemplar for computational work going forward.</p> <p>However, I do want to carve out space for approaches to the digital archive that are bibliographically informed while being experimental, exploratory, even playful. The term ‚Äúspeculation‚Äù has a long history in the digital humanities, as a term that pairs the technical and ludic. In an essay from the 2004 volume that named the field of digital humanities, Johanna Drucker and Bethany Nowviskie write about the tensions inherent in the term ‚Äúspeculative computing‚Äù:</p> <blockquote> <p>Speculative computing is a technical term‚Ä¶It refers to the anticipation of probable outcomes along possible forward branches in the processing of data. Speculation is used to maximize efficient performance‚Ä¶Logic-based, and quantitative, the process is pure <em>techne</em>, applied knowledge, highly crafted, and utterly remote from any notion of <em>poiesis</em> or aesthetic expression. Metaphorically, speculation invokes notions of possible worlds spiraling outward from every node in the processing chain, vivid as the rings of radio signals in the old RKO studios film logo. To a narratologist, the process suggests the garden of forking paths, a way to read computing as a tale structured by nodes and branches.</p> </blockquote> <p>For Drucker and Nowviskie, speculative computing is evocative almost despite itself, ‚Äúconjuring images of unlikely outcomes and surprise events, imaginative leaps across the circuits that comprise the electronic synapses of digital technology.‚Äù Prediction is interpretation in this framework: a model of thought instantiated in code. For the digital humanities, this idea is important because ‚ÄúSpeculative approaches make it possible for subjective interpretation to have a role in shaping the <em>processes</em>, not just the <em>structures</em>, of digital humanities.‚Äù<sup id="fnref:Drucker" role="doc-noteref"><a href="#fn:Drucker" class="footnote" rel="footnote">8</a></sup></p> <p><em>In the longer version of this paper, I here turn to Nowviskie‚Äôs more recent work, drawing on Afrofuturism, to imagine ‚Äúspeculative collections‚Äù that ‚Äúactivate imaginations‚Äîboth their users‚Äô imaginations and those of the expert practitioners who craft and maintain them?‚Äù<sup id="fnref:Nowviskie" role="doc-noteref"><a href="#fn:Nowviskie" class="footnote" rel="footnote">9</a></sup> as well as Lauren Klein‚Äôs mandate for scholars of early American literary history to develop ‚ÄúA speculative aesthetics of early American literature‚Äù (439).<sup id="fnref:Klein" role="doc-noteref"><a href="#fn:Klein" class="footnote" rel="footnote">10</a></sup> We can delve into these in the Q&amp;A if folks are interested</em></p> <p>What I am calling speculative bibliography is speculative in both senses Nowviskie and Drucker elicit. It is an anticipatory processing of bibliographic data in order to maximize possible paths of discovery‚Äînot all operations produce meaningful literary-historical insights, but some do‚Äîand it is also an imaginative act that asks how the archive might make meanings if differently arranged and juxtaposed.</p> <h3 id="speculative-editions">Speculative Editions</h3> <p>In the <em>Viral Texts</em> project, we reorder the historical newspaper archive to see not individual newspapers over time, but the tendrils of textual repetition, quotation, circulation, and theft that linked papers and readers together. Since the beginning of the project we have wrestled with how best to make our data available to other scholars to argue with or against. On the one hand, when we publish an article, its arguments are based on particular texts: the hundreds of reprints of the poem ‚ÄúBeautiful Snow,‚Äù for instance, or of a listicle outlining the habits of successful young businessmen. The reprints from which we developed our argument were identified by a particular run of our algorithm and exist as data in a spreadsheet, itself a historically-specific textual artifact. We recognize that scholars reading our 2016 <em>American Periodicals</em> article should be able to refer to the 276 reprints of ‚ÄúBeautiful Snow‚Äù we consulted when writing it, and we dutifully published a spreadsheet alongside that article that includes all of the texts we cite in it. Ultimately, however, our argument is not about any particular reprint of ‚ÄúBeautiful Snow,‚Äù but about the event of that poem across the country and the world: the many reprints, the readers who loved it, the poets who parodied it and parodied its parodies, the editors who debated its authorship. And our picture of that event continually shifts as we refine our reprint detection methods and add new historical newspaper data to our inquiries. I want readers to find those 276 reprints from 2016, of course, but I also want them to find the 291 reprints we know of in 2020, or the 500 (he wrote optimistically) we will know of in 2022.</p> <p>As we develop the <em>Viral Text</em> project book (<a href="https://manifold.umn.edu/projects/going-the-rounds" target="_blank" rel="noopener noreferrer"><em>Going the Rounds</em></a>, University of Minnesota Press), we are experimenting with an approach that weaves together textual editing and computational speculation. For each work that we write about‚Äîby which I mean a set of witnesses that we would identify as reprints of the same work‚Äîwe create a clean transcription from one witness we specifically reference. <a href="https://www.dropbox.com/sh/74nl5ook9540xbu/AACBicW5ppS8YZ5lteIUKMika?dl=0" target="_blank" rel="noopener noreferrer">These transcriptions, which we refer to as ‚Äúanchor texts,‚Äù</a> become stable points of reference incorporated into each new iteration of our algorithm: a seed around which reprints of that particular text will be clustered in subsequent analyses. In each new dataset we create, these transcriptions are the reference points that allow researchers to quickly home in on familiar texts, while allowing textual clusters to shift as we experiment with the parameters of our algorithm or expand the source data we analyze. Thus when the book is published, readers will be able to find the texts on which its arguments are based in our public database, but also to see how our picture of nineteenth-century newspaper reprinting is evolving in real time.</p> <p>By providing a stable bibliographic reference point within a speculative computing environment, these transcriptions also enable us to better understand and critique the effects made by changes to our algorithm. From the computer science perspective of our project, we have always wrestled with the lack of ‚Äúground truth‚Äù‚Äîa well-known and described dataset in which to test whether a method is returning reliable results. No index or hand-tagged archive of nineteenth-century newspaper reprinting exists‚Äîeven at a relatively small scale‚Äîthat we could use to ensure we are finding the reprints we should be finding before applying our methods across a larger, unknown collection. Even from the CS side, then, our work is speculative, and we have relied on estimates of recall due to the fundamental incompleteness and uncertainty of historical data. Anchor text transcriptions allow us to directly compare textual clusters from experiment to experiment and see precisely how changed parameters affect our results.</p> <p>By taking a speculative approach to building bibliographies, the <em>Viral Texts</em> project puts into practice a method for identifying sets of formally-related texts worthy of study, by virtue of their duplication, from the massive archive of nineteenth-century newspapers. To expand our scope a bit, we might imagine other algorithms trained to recognize particular historical fonts, or to identify woodcuts within a collection of historical books. As a complement to Bode‚Äôs ‚Äúscholarly edition of a literary system,‚Äù I would propose the <em>speculative edition</em>: all texts associated through a single computational model. We should not take the probabilities underlying speculative bibliography as <em>the truth</em> about literary history, but as propositions that demand testing and argumentation. Given the scope of our digitized collections, however, I would argue that many branching, speculative bibliographies will be necessary to identify fruitful paths of scholarly inquiry, and must proceed in dialogue with the careful editing and curation undertaken by textual scholars. Too often we separate our <em>data</em> from our <em>analysis of the data</em>, as if the one exists simply to illuminate the other. To resist this impulse, we need to integrate our computational experiments into our archival interfaces, provided as alternative paths into and through material.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:McGann" role="doc-endnote"> <p>McGann, Jerome. <em>A New Republic of Letters: Memory and Scholarship in the Age of Digital Reproduction</em>. Cambridge: Harvard University Press, 2014.¬†<a href="#fnref:McGann" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Senchyne" role="doc-endnote"> <p>Senchyne, Jonathan. <em>The Intimacy of Paper in Early and Nineteenth-Century American Literature</em>. Amherst: University of Massachusetts Press, 2019.¬†<a href="#fnref:Senchyne" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Tanselle" role="doc-endnote"> <p>Tanselle, G. Thomas. ‚ÄúThe Bibliographical Concepts of ‚ÄòIssue‚Äô and ‚ÄòState.‚Äô‚Äù <em>The Papers of the Bibliographical Society of America</em> 69, no. 1 (1975): 17‚Äì66.¬†<a href="#fnref:Tanselle" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:OCR" role="doc-endnote"> <p>Cordell, Ryan. ‚Äú‚ÄòQ i-Jtb the Raven‚Äô: Taking Dirty OCR Seriously.‚Äù <em>Book History</em> 20 (2017): 188‚Äì225.¬†<a href="#fnref:OCR" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Vee" role="doc-endnote"> <p>Vee, Annette. <em>Coding Literacy</em>. Cambridge: MIT Press, 2017.¬†<a href="#fnref:Vee" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Tenen" role="doc-endnote"> <p>Tenen, Dennis. <em>Plain Text: The Poetics of Computation</em>. Palo Alto: Stanford University Press, 2017.¬†<a href="#fnref:Tenen" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Bode" role="doc-endnote"> <p>Bode, Katherine. <em>A World of Fiction: Digital Collections and the Future of Literary History.</em> Ann Arbor: University of Michigan Press, 2018.¬†<a href="#fnref:Bode" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Drucker" role="doc-endnote"> <p>Drucker, Johanna, and Bethany Nowviskie. ‚ÄúSpeculative Computing: Aesthetic Provocations in Humanities Computing.‚Äù In <a href="http://www.digitalhumanities.org/companion/" target="_blank" rel="noopener noreferrer"><em>Companion to Digital Humanities</em></a>, edited by Susan Schreibman, Ray Siemens, and John Unsworth, Hardcover. Blackwell Companions to Literature and Culture. Oxford: Blackwell Publishing Professional, 2004.¬†<a href="#fnref:Drucker" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Nowviskie" role="doc-endnote"> <p>Nowviskie, Bethany. ‚ÄúSpeculative Collections.‚Äù In Bethany Nowviskie, 2016. <a href="http://nowviskie.org/2016/speculative-collections/" target="_blank" rel="noopener noreferrer">http://nowviskie.org/2016/speculative-collections/</a>.¬†<a href="#fnref:Nowviskie" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Klein" role="doc-endnote"> <p>Klein, Lauren F. ‚ÄúSpeculative Aesthetics.‚Äù <em>Early American Literature</em> 51, no. 2 (July 13, 2016): 437‚Äì45. <a href="https://doi.org/10.1353/eal.2016.0020" target="_blank" rel="noopener noreferrer">https://doi.org/10.1353/eal.2016.0020</a>.¬†<a href="#fnref:Klein" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>