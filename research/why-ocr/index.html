<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Why You (A Humanist) Should Care About Optical Character Recognition | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/why-ocr/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Why You (A Humanist) Should Care About Optical Character Recognition</h1> <p class="post-meta">January 10, 2019‚Ä¢ Ryan Cordell</p> <p class="post-tags"> <a href="/blog/2019"> <i class="fas fa-calendar fa-sm"></i> 2019 </a> </p> </header> <article class="post-content"> <p>Yesterday <a href="http://www.ccs.neu.edu/home/dasmith/" target="_blank" rel="noopener noreferrer">David Smith</a> and I announced the release of <a href="https://ocr.northeastern.edu/report/" target="_blank" rel="noopener noreferrer">‚ÄúA Research Agenda for Historical and Multilingual Optical Character Recognition,‚Äù</a> a report funded by the Andrew W. Mellon Foundation and conducted in consultation with the NEH‚Äôs Office of Digital Humanities and the Library of Congress. These groups realized that many of the digital humanities projects they support struggle with similar issues related to the quality of their source text data. They asked us to survey the current state of OCR for historical and multilingual documents, and to recommend concrete steps that researchers, implementors, and funders could take to make progress in creating more reliable and representative OCR data over the next five to ten years.</p> <p>We were fortunate to work with a generous, brilliant community of scholars from the humanities, libraries, computer science, and industry to research this topic and craft a series of recommendations we hope could indeed move this area forward dramatically. If there‚Äôs an idealism to some of our recommendations, that‚Äôs because in the course of researching and writing this report we became convinced that concerted work on OCR, particularly in certain historical or language collections, could have dramatic results. Please <a href="https://ocr.northeastern.edu/report/" target="_blank" rel="noopener noreferrer">read the report</a>‚Äîit was a labor of love for us and so many who helped us, and we think there are lots of inspiring ideas from the community reflected there. The report came out yesterday and we‚Äôre already seeing the beginnings of a broader conversation that <a href="https://twitter.com/ryancordell/status/1083362956853870592" target="_blank" rel="noopener noreferrer">illuminates work we (perhaps inevitably) missed in our initial research</a>. As I wrote on Twitter, I‚Äôll be thrilled if the report facilitates needed but missed discussions between research communities, including those discussions we missed in the report itself.</p> <p>This post doesn‚Äôt attempt to recap the entire report. Instead, here I want to address my humanities colleagues who might be uncertain why a report about something called optical character recognition should matter to them. In my 2017 <em>Book History</em> article, <a href="https://ryancordell.org/research/qijtb-the-raven/">‚Äú‚ÄòQ i-jtb the Raven‚Äô: Taking Dirty OCR Seriously‚Äù</a> I argued that OCR constitutes an important intellectual subject for book historians, but here I make a more direct and practical argument that humanities scholars should be aware of and even participate in current research aimed at improving OCR algorithms. As we articulate in the report, the expertise of humanities scholars is desperately needed, in collaboration with computer scientists, if we want make substantive progress improving OCR for the kinds of materials we most care about. Below, I answer a series of questions I hope will explain (in non-technical language) what OCR is, why it should matter to humanists, and what we might contribute to its future.</p> <h2 id="what-is-ocr">What is OCR?</h2> <p>When someone scans a page from a book, newspaper, or other textual source, the computer does not initially recognize that the image includes text. The scan is essentially a picture of the page: an image file such as those created when you take a snapshot on your phone‚Äôs camera. A human looking at that picture would see readable text in the image, but would not be able to use their computer‚Äôs search functions to find those same words. A researcher hoping to do more complex forms of data mining would be out of luck, at least if they hoped to do something with the text of the page‚Äîcount word frequencies, build a topic model, &amp;c. &amp;c.‚Äîas opposed to its visual elements.</p> <p>Optical character recognition (OCR) software is a type of artificial intelligence software designed to mimic the functions of the human eye and brain and discern which marks within an image represent letterforms or other markers of written language. OCR scans an image for semantically-meaningful material and transcribes what language it finds into text data. Typically OCR is used in situations where manual transcription would be too costly or time consuming‚Äîa subjective designation to be sure‚Äîsuch as when a large corpus has been scanned. Relative to manual transcription, OCR is a quick and affordable means for creating computable text data from a large collection of images.</p> <h2 id="who-uses-ocr">Who Uses OCR?</h2> <p>You, probably, perhaps without realizing. If you ever search in a large-scale digital archive such as <a href="https://books.google.com/" target="_blank" rel="noopener noreferrer">Google Books</a>, <a href="https://www.hathitrust.org/" target="_blank" rel="noopener noreferrer">HathiTrust</a>, <a href="https://eebo.chadwyck.com/home" target="_blank" rel="noopener noreferrer">EEBO</a>, <a href="https://www.gale.com/primary-sources/eighteenth-century-collections-online" target="_blank" rel="noopener noreferrer">ECCO</a>, or a historical newspaper archive such as <a href="https://chroniclingamerica.loc.gov/" target="_blank" rel="noopener noreferrer">Chronicling America</a>, then your searches are operating on OCR-derived text data. That text data is often hidden in various ways by the interfaces of digital archives (a practice <a href="https://ryancordell.org/research/qijtb-the-raven/">I question strongly here</a>), but nonetheless if you use these kinds of archives‚Äîas I would argue most humanities scholars do, at least occasionally‚Äîthen you rely on the output of OCR algorithms. In other words, OCR is a fundamental element of our digital research infrastructure that‚Äôs also easily overlooked because we tend to focus on the images of historical pages rather than the underlying text data that helped us find them. There are many historical texts that have been hand-transcribed and encoded through <a href="http://www.tei-c.org/" target="_blank" rel="noopener noreferrer">a standard such as TEI</a>, such as digital editions like those of the <a href="https://www.wwp.northeastern.edu/" target="_blank" rel="noopener noreferrer">Women Writers Project</a>, but a substantial percentage‚Äîin fact a large majority, by sheer numbers of pages‚Äîof digitized humanities texts are constituted through OCR. In other words, even if you‚Äôve never heard of OCR it may nonetheless be important or even essential to your research and teaching.</p> <h2 id="isnt-that-a-good-thing">Isn‚Äôt That a Good Thing?</h2> <p>Mostly, yes, I would argue. OCR has enabled a proliferation of research across media that were previously much trickier to delve into. The use of historical newspapers, to cite an example close to my heart, has exploded in scholarship of the past two decades, largely due to the kinds of access enabled by searchable text data, which can make vast collections navigable, tractable. The access provided by search is not an unmitigated good (see <a href="http://muse.jhu.edu/article/527016" target="_blank" rel="noopener noreferrer">Ian Milligan‚Äôs article ‚ÄúIllusionary Order‚Äù</a> for a good primer on its potential dangers) but it is, to my mind, an overall good.</p> <p>But it is also true that OCR can produce, in a beautiful term I‚Äôve borrowed from computer science, ‚Äúerrorful‚Äù data. The admittedly simplified version is this: OCR was largely developed to process typewritten, English-language, mid-twentieth-century business documents. With that kind of input, OCR is remarkably reliable, transcribing with accuracy in the upper 90 percents. Turn an OCR engine toward historical documents, however, with distinct typography, complex layouts, torn pages, smeared ink, and any number of features those OCR engines were not trained to discern, then the reliability of OCR transcription declines precipitously. A famous example of this is the German fraktur typeface‚Äîwhat we sometimes call blackletter in English‚Äîwhich was used in most German books and newspapers through the early 20th century and which OCR engines have not historically been well trained to recognize or transcribe. For multilingual documents and languages outside English, particularly those do not use Latin script, the problem becomes even more acute and error rates significantly higher.</p> <p>What does this mean for humanities research? Well it could mean that when you search for a given word or phrase in a large-scale archive, you miss potential matches because instead of transcribing ‚Äúquoth the raven‚Äù the OCR engine transcribed ‚Äúq i-jtb the raven.‚Äù In that example, drawn from my <em>Book History</em> article, the error resulted because of uneven inking in the original newspaper that made the ‚Äúu‚Äù and ‚Äúo‚Äù letterforms look just different enough from those letters in its training data that the OCR engine misrecognized them. For some tasks, even fairly high error rates may be acceptable: a word that‚Äôs truly a keyword in a particular document is likely to be repeated, and the more often a word is repeated the more likely it is that some instances will be transcribed correctly. One major problem we outline in our report is that we do not have a clear sense of what thresholds are acceptable for various tasks. How good must OCR be for us to rely on the results of a keyword search? Of a topic model? We have largely resulted on instinct in making these sorts of judgments, but we might be able to do better.</p> <h2 id="so-its-useless-then">So It‚Äôs Useless Then?</h2> <p>No. For me, it is so essential that our conclusions about OCR not end with throwing up our hands in despair. My own scholarly interest in OCR largely began from a creeping frustration with how the technology was invoked in humanities presentations. It‚Äôs become a conference trope to display a slide showing the terrible OCR underlying a given archive as a kind of public shrug, ‚Äúwhat can you do, amiright?‚Äù Everyone laughs and moves on without thinking all that hard about the OCR or the assumptions baked into that moment of collective apathy. Rarely does the presenter engage with precisely why and how that particular OCR is useless: what are you seeking to learn from it? What level of reliability would you need to learn what you want to learn? What tasks might be possible with existing OCR?</p> <p>It‚Äôs even less common for the presenter to consider what might be done to improve the situation: that‚Äôs the task, such presentations seem to concede, for computer scientists and corporations, and they don‚Äôt care about our concerns. I don‚Äôt want to claim that every corporation managing an OCR archive cares deeply about the concerns of humanities researchers, particularly those working in areas or fields they might consider niche. But if researching and writing this report taught me anything, it‚Äôs that there is significantly more opportunity for interdisciplinary cooperation around these issues than we typically credit, and more goodwill about our concerns and areas of interest than we imagine in our moments of conference cynicism. This work has made me hopeful, not just that OCR can be improved but that humanities scholars can be central contributors to its future.</p> <p>In the recommendations of the report, you will see that the most pressing research in the field will require extensive development of training corpora: accurate transcriptions of materials in a given domain that can be used to train an OCR system how to recognize the textually-meaningful elements in images drawn from that domain. In other words, the most pressing OCR research will require the expertise of humanities domain specialists: book and textual historians, scholars of languages and writing systems, scholars of particular genres or historical periods. In response to the report, Michael Gossett <a href="https://twitter.com/michaeljgossett/status/1083103235601240064" target="_blank" rel="noopener noreferrer">wrote on Twitter</a>, ‚ÄúOne sees an entire future of collaborative scholarship here.‚Äù I agree strongly. There is enormous potential in OCR research for meaningful, important collaboration across a range of fields, but particularly across the humanities, libraries, and computer science. For me this is the central reason humanists should care about OCR: not to bemoan its current state but to help imagine its future.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>