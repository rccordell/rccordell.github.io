<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>What Makes Computational Evidence Significant for Literary-Historical Argument? | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/dh/computational-evidence-for-literary-historical-argument/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">What Makes Computational Evidence Significant for Literary-Historical Argument?</h1> <p class="post-meta">July 27, 2017</p> <p class="post-tags"> <a href="/blog/2017"> <i class="fas fa-calendar fa-sm"></i> 2017 </a> </p> </header> <article class="post-content"> <p><em>I‚Äôve been invited to submit an initial position paper for the <a href="https://rrchnm.org/news/arguing-with-digital-history-workshop-to-address-a-central-problem-in-digital-history/" target="_blank" rel="noopener noreferrer">Arguing with Digital History</a> workshop, to be held at The Roy Rosenzweig Center for History and New Media in September 2017. Following <a href="https://medium.com/@ProfessMoravec/digital-history-and-historical-argumentation-26e15d729840" target="_blank" rel="noopener noreferrer">Michelle Moravec‚Äôs lead</a>, I‚Äôd like to offer my response publicly, most especially because of the ways these thoughts were written alongside and intertwine with <a href="https://twitter.com/Zoe_LeBlanc/status/889668601153761280" target="_blank" rel="noopener noreferrer">Zoe LeBlanc‚Äôs provocative questions</a> on Twitter and the valuable thread of responses to them from the community. We have been asked to come to the workshop prepared to modify our views as a result of the discussion, so I‚Äôd like to be clear that these are initial and deliberately provocative thoughts which are very open to amendment or even wholesale rethinking. Also, we were asked to keep these position papers to two pages, which I‚Äôm already a bit over, so I apologize if some lines of thought feel truncated. There is so much more to say about‚Ä¶well‚Ä¶about all of this.</em></p> <p>Argumentation for digital history stumbles over the ontology of its evidence. I‚Äôm writing here about corpus-scale analysis, the digital methodology I know best from my work on the <a href="http://viraltexts.org" target="_blank" rel="noopener noreferrer">Viral Texts project</a>, and variously named by terms like ‚Äúdistant reading‚Äù or ‚Äúcultural analytics.‚Äù Though the specifics of these methods are hotly debated, we might gather them under the sign of scale, a notion of ‚Äúreading‚Äù‚Äîand I‚Äôd like to make that word do more work than perhaps it should‚Äîacross wider sets of materials than was typical for humanists prior to computational methods.¬†</p> <p>Recently in <em>literary</em>-historical circles, <a href="https://katherinebode.files.wordpress.com/2014/07/bode-article_mlq_final.pdf" target="_blank" rel="noopener noreferrer">Katherine Bode has inspired a much-needed discussion</a> about the corpora on which computational analyses are based. Drawing on traditions of book history and textual scholarship, Bode critiques Moretti and Jockers, in particular, as metonymies for distant reading approaches:</p> <blockquote> <p>Moretti and Jockers construct literary systems as comprised of singular and stable entities, while also imagining that they capture the complexity of such systems in the process. In fact, because their datasets miss most historical relationships between literary works, their analyses are forced to rely upon basic features of new literary production to constitute both the literary phenomenon requiring explanation, and the explanation for it.</p> </blockquote> <p>Most incisively, Bode shows how much ‚Äúdistant reading‚Äù work reconstitutes the primary assumption of close reading: ‚Äúthe dematerialized and depopulated understanding of literature in Jockers‚Äôs work enacts the New Criticism‚Äôs neglect of context, in a manner rendered only more abstract by the large number of ‚Äòtexts‚Äô under consideration.‚Äù The problem may be, in other words, not that computational analysis departs from analog methods, but that we interpret the results of corpus-level analysis too much like we interpret individual texts. To be provocative, I might rephrase to say that we don‚Äôt yet as a field understand precisely how corpus-scale phenomena make their meaning, or how those meanings relate back to codex-scale artifacts.</p> <p>I can pick on myself to clarify what I mean (and here I‚Äôm paraphrasing some points I make in <a href="http://ryancordell.org/research/scale-as-deformance/">‚ÄúScale as Deformance‚Äù</a>). In the Viral Texts project, we have developed sophisticated methods for identifying reprinted pieces across nineteenth-century newspaper corpora. When we find, say, a popular science article that was reprinted 150 times around the world, that cluster of texts can help us think about circulation, genre, and networks of influence among editors in the period. When compared with other texts circulating around the same time, it can teach us something about the concerns, interests, and priorities of readers and editors as well. But a textual cluster is not singular‚Äîit is in fact defined by its multiplicity‚Äîand the meaning of its reprinting does not evenly distribute across the 150 individual witnesses that make up the cluster. Some of the nineteenth century editors who reprinted a given piece, and some of the nineteenth century readers who read it, would have known it was ‚Äúmaking the rounds,‚Äù and may have had a sense of its wide reach. However, no nineteenth-century person had the corpus-scale perspective on a given cluster that we do from the wild surmise of a CSV file. An article embedded in a complex textual system signifies in both networked and highly local ways, but we cannot easily extrapolate from the meanings we assign a cluster (among many other clusters) to the meanings of its constituent texts, much less the readers of those texts.</p> <p>There has been much written (including by me!) about the need for <a href="http://www.digitalhumanities.org/dhq/vol/7/1/000144/000144.html" target="_blank" rel="noopener noreferrer">zoomable</a>, <a href="http://www.digitalhumanities.org/dhq/vol/8/3/000183/000183.html" target="_blank" rel="noopener noreferrer">scalable</a>, or <a href="http://www.themacroscope.org/2.0/" target="_blank" rel="noopener noreferrer">macroscopic reading</a> that puts insights drawn from distinct scales <a href="http://www.jstor.org/stable/10.2979/victorianstudies.54.1.69" target="_blank" rel="noopener noreferrer">in conversation</a>. However, I would argue that thus far digital (literary) history has not adequately theorized the middle ground between corpus and codex, or developed methods that can meaningfully relate corpus-scale patterns to individual texts without pretending that patterns at each scale can be understood under the same interpretive paradigm. I would go so far as suggesting the macroscope is not the most useful metaphor for structuring digital historical arguments, as it implies a seamless movement between scales that the realities of analysis belie. Perhaps new metaphors are needed for expressing the continuities and disjunctures between analyses at distinct scales.</p> <p>Why do scholarly metaphors matter to argument in digital history? We have been so insistent on seamless movement between scales‚Äîand so resistant to appearing like positivists or cliometricians‚Äîthat we have failed to develop field-specific paradigms for interpreting the results of corpus-scale text analyses. What standards we have are imported from other fields such as corpus linguistics, but as such they must be rearticulated and renegotiated for every article, website, or book we publish. More importantly, as Scott Weingart has shown, <a href="http://www.scottbot.net/HIAL/index.html@p=6279.html" target="_blank" rel="noopener noreferrer">‚Äúmethodology appropriation is <em>dangerous</em>‚Äù</a> and, frankly, our colleagues are right to look with skepticism on methods imported wholesale from other disciplines. Ted Underwood‚Äôs recent <a href="http://www.digitalhumanities.org/dhq/vol/11/2/000317/000317.html" target="_blank" rel="noopener noreferrer">‚ÄúA Genealogy of Distant Reading‚Äù</a> offers important context here, noting that, ‚Äúlinguistics may be looming a little too large in the foreground of contemporary narratives about distant reading, so much that it blocks our view of other things,‚Äù including forebears in humanities fields prior to computation. We needn‚Äôt impugn the practices of disciplines from which we could indeed learn much, but we should insist that imported methodologies be understood, examined, and <em>reimagined</em> to meet the specific needs of literary or historical research.</p> <p>To cite a specific example, computational historical arguments require models for effective sampling, which might help clarify how analyses at distinct scales relate to one another. To put it bluntly, we have no idea what an effective sample from a literary or historical corpus should look like. What random sample of novels (or newspaper pages, or museum artifact descriptions) could I topic model from a given corpus with some confidence it can represent the larger collection? As humanists we are well prepared to nuance notions of ‚Äúrepresentativeness,‚Äù but those necessary caveats cannot leave us with the answer that sampling must be reinvented anew for every corpus and every study, which would indeed leave us explicating data in much the same way Cleanth Brooks explicated ‚ÄúOde on a Grecian Urn.‚Äù We also cannot default to the answer that humanists can only sample in the same way that sociologists or political scientists or linguists do. My point is: we lack even rough guidelines around which to debate, but we could have those conversations.</p> <p>I will end with a too-brief reflection on significance: a word with quite specific meanings in quantitative fields that we cannot port entire into literature or history. In the Viral Texts project, there are certain features of nineteenth-century newspapers we can only study‚Äîat least as of yet‚Äîthrough their presence, which makes their statistical significance difficult to gauge. When I write, for instance, that <a href="http://ryancordell.org/research/reprinting-circulation-and-the-network-author-in-antebellum-newspapers/">‚Äúinformation literature‚Äù is an interesting feature of widely-reprinted newspaper texts in the nineteenth century</a>, my standard of significance comes from codex-scale work. I have read a lot of nineteenth century newspapers and so understand these genres in the context of their medium. From that starting point, information literature seems more common in those pieces we identify as widely reprinted than I would expect. But I cannot estimate the presence of ‚Äúinformation literature‚Äù in articles that <em>were not</em> reprinted, while the fragmentary coverage of our corpora‚Äîto return to Bode‚Äîensures that many reprinted pieces are not identified as such, as their source newspapers are either not digitized or are included in other corpora to which we do not have access.</p> <p>While I mostly agree with <a href="http://scottbot.net/argument-clinic/" target="_blank" rel="noopener noreferrer">Weingart‚Äôs more recent claims</a> that ‚Äú[c]omputational history has gotten away with a lot of context-free presentations of fact,‚Äù I would insist that comparative statistics are not the only‚Äîor often the most compelling‚Äîmethod for building such context. When I write about ‚Äúinformation literature‚Äù as significant don‚Äôt mean that it appears more often than it would in some theoretical null corpus. I am not talking about a p-value. As Weingart mentions, however, we might look also toward other kinds of ‚Äúdeviations from expectations,‚Äù including expectations set by previous field literature. I note the prevalence of reprinted information literature as conspicuous given the dearth of critical attention paid to information literature in prior literary-historical criticism. Very few scholars have attended seriously to short, popular science; trivia; recipes; household tips; listicles; and related genres despite the fact that they filled newspapers and circulated around the globe. There might be a reason to work toward measuring the statistical significance of information literature. We could train a classifier using our extracted information literature, for instance, and then attempt to discern how many non-reprinted newspaper texts are information literature. From there we could compare the proportion of the genres in reprints to their proportion in the larger corpus. But if our goal is to make arguments that will impact literary or historical criticism, it is far more essential that the patterns we trace computationally speak to significant questions or gaps of attention in our disciplines. There is nothing wrong with using statistical measures as evidence, but such measures cannot be the extent of our accounts.</p> <p>For corpus-scale analyses to resonate with humanities scholars, we must be ‚Äúmore ambitious,‚Äù <a href="http://miriamposner.com/blog/whats-next-the-radical-unrealized-potential-of-digital-humanities/" target="_blank" rel="noopener noreferrer">as Miriam Posner has urged</a>, in ‚Äúrebuilding the machinery of the archive and database so that it doesn‚Äôt reproduce the logic‚Äù of exclusion and marginalization embedded into computational tools. Posner worries that digital humanists ‚Äúseem happy to flatten the world into known data structures‚Äù to which I would add that we seem likewise happy to flatten our <em>data mining</em> to methods and measures established in other disciplines. Part of rebuilding the machinery requires us to articulate discipline-specific models for relating text and corpus without collapsing them into each other. I am drawn again and again to Lauren Klein‚Äôs <a href="http://lklein.com/2015/06/the-carework-and-codework-of-the-digital-humanities/" target="_blank" rel="noopener noreferrer">description of topic modeling</a> as ‚Äúa technique that stirs the archive,‚Äù and such stirring remains to my mind the most compelling use for computational analyses in literary-historical corpora. But we need a better vocabulary for describing the composition of our archives, the outcomes of our archival remixing, <em>and</em> the interpretive space in between.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>