<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Towards a Bibliography for AI Systems | Ryan C. Cordell</title> <meta name="author" content="Ryan C. Cordell"/> <meta name="description" content="Book history, digital humanities, old newspapers, and information sciences "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üóûÔ∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ryancordell.org/research/aibibliography/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://ryancordell.org/"><span class="font-weight-bold">Ryan</span> C. Cordell</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">links</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="http://cv.ryancordell.org/" target="_blank" rel="noopener noreferrer">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/statements/">Dossier Statements</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="http://viraltexts.org/" target="_blank" rel="noopener noreferrer">Viral Texts Project</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href=""></a><a rel="noopener noreferrer" href="https://bsky.app/profile/ryancordell.bsky.social" target="_blank">BlueSky</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Towards a Bibliography for AI Systems</h1> <p class="post-meta">April 21, 2023‚Ä¢ Ryan Cordell</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </header> <article class="post-content"> <p><em>The following remarks were prepared for The Andrew W. Mellon Society of Fellows in Critical Bibliography <a href="https://rarebookschool.org/all-programs/events/preserving-and-analyzing-digital-texts/" target="_blank" rel="noopener noreferrer">forum on ‚ÄúPreserving and Analyzing Digital Texts.‚Äù</a></em></p> <p>In 2022 new AI image, text, video, and music models seem to appear every week, spurring waves of attention in social media and forcing constant reconsiderations of the horizons of such technology, as well as their implications to research and teaching. Most dramatic was the release of ChatGPT,<sup id="fnref:ChatGPT" role="doc-noteref"><a href="#fn:ChatGPT" class="footnote" rel="footnote">1</a></sup> a large language model developed by OpenAI and released to much fanfare and critique in late 2022. Since that release this model has generated significant enthusiasm and anxiety among different stakeholders, from companies eager to integrate it into applications from writing assistance to search, to professors worried students will outsource writing their college papers to the technology.<sup id="fnref:ChatGPTDebate" role="doc-noteref"><a href="#fn:ChatGPTDebate" class="footnote" rel="footnote">2</a></sup> The debate about ChatGPT has in many ways become a proxy for larger debates about algorithmic accountability, fairness, and reliability. In the mere months since ChatGPT was released, a yet newer generation large language model, which OpenAI promises will be ‚Äúmore creative and collaborative than ever before,‚Äù has been released as GPT-4.<sup id="fnref:GPT4" role="doc-noteref"><a href="#fn:GPT4" class="footnote" rel="footnote">3</a></sup> The pace of these AI announcements has certainly contributed to the sense that everyone, but perhaps especially those working in educational sectors, are scrambling to keep up.</p> <p>At the core of many of the debates around AI models of culture‚Äîwhether text, image, audio, or video‚Äîis anxiety about corporate control, proprietary software, and ‚Äúblack-box‚Äù systems. These models are machine learning systems, trained on massive amounts of data, but OpenAI and other companies typically do not disclose the exact composition of their models‚Äô training data, making it difficult for users to ascertain the reliability, representativeness, or limitations of the models, or their relevance to different domains. That the companies building these models wish to obscure their provenance and functions, however, does not mean those things are unavailable for study and analysis.</p> <p>This paper argues first that responding to this moment mandates developing toolkits for structural analyses of AI systems, and second that such methods should bring together two related traditions: the sociological school of bibliography and book history, which forefronts the linked technological, social, economic, and artistic contexts through which books and related media come into being, and the growing set of methods gathered under the mantle of ‚Äúdata archaeology,‚Äù which seek to outline similarly linked contexts through which datasets are created, distributed, and accessed. Such a bibliography for AI systems triangulates between materiality, infrastructure, and labor to describe the systems of digitization, archiving, extraction, and representation that lead from digitized and born-digital sources to the strings of text output by LLMs in response to user prompts. Just as D.F. McKenzie argued bibliographers should ‚Äúdescribe not only the technical but the social processes of [texts‚Äô] transmission,‚Äù AI systems require a bibliography that studies the diffuse and often obscured sociology of textual data.<sup id="fnref:McKenzie" role="doc-noteref"><a href="#fn:McKenzie" class="footnote" rel="footnote">4</a></sup> In prior work I have argued for the value of <a href="https://www.degruyter.com/view/journals/angl/138/3/article-p519.xml" target="_blank" rel="noopener noreferrer">‚Äúspeculative bibliographies‚Äù</a> for historical research, by which I primarily described enumerative bibliographies ‚Äúin which textual associations are constituted propositionally, iteratively, and (sometimes) temporarily, as the result of probabilistic computational models.‚Äù<sup id="fnref:speculative" role="doc-noteref"><a href="#fn:speculative" class="footnote" rel="footnote">5</a></sup> Here, however, I advocate for speculative analytical or descriptive bibliographies that hypothesize about the material bases of closed AI systems based on extant clues about their composition and through reverse engineering of their outputs.</p> <p>I approach this project first from the perspective of bibliography in part because of my own training, but also because the field offers a useful orientation and toolkit for the humanistic investigation of technical systems. Bibliographic methods were first developed to make predictions about a text‚Äôs material construction, editing, and significance from clues rooted historically in systems of production‚Äîthe infrastructures of print culture. Signatures, chain lines, watermarks, and other physical clues were not placed in books deliberately by papermakers, printers, or binders for scholars, but are artifacts of production‚Äîpapermaking, printing, binding‚Äîthat scholars discovered could be reverse engineered in order to analyze the details of that production. In the late 20th century‚ÄîI use this formulation even as I turn to dust‚Äîbibliographers such as Thomas Tanselle began thinking about how bibliographic frameworks could adapt to describe the increasingly dominant modes of electronic textual production, such as word processing, that would produce bookish objects going forward. Similarly to books in the printing press era or documents in the word processing era, complex computational systems in 2023 are not constructed with an eye toward transparency or material analysis, but leave clues that can be collated and theorized.</p> <p>In addition to these historical parallels, I would also argue that LLMs are ripe for bibliographical analysis because they are, specifically and substantively, deeply bookish. We know they were trained, at least in part, on book data‚Äîas well as other forms familiar to bibliographers, such as academic journals, newspapers, and magazines. We might describe AI systems as ‚Äúpastiche engines,‚Äù remixing existing cultural artifacts, rather than producing new ideas. This is both a critique and a means of locating these technologies within the continuum book historians and bibliographers study, and in fact places them in dialogue with a range of historical media that are also based in overlay, pastiche, and remix‚Äîmedia such as commonplace books, scrapbooks, palimpsests, or newspapers. The reprinting we study in the <a href="https://viraltexts.org/" target="_blank" rel="noopener noreferrer"><em>Viral Texts</em> project</a> is not identical to the species of text reuse produced by an LLM, but the practices share a family resemblance. As Ted Underwood has written, ‚Äúthe fuzzy, context-specific models produced by machine learning have a lot in common with the family resemblances historians glimpse in culture.‚Äù<sup id="fnref:underwood" role="doc-noteref"><a href="#fn:underwood" class="footnote" rel="footnote">6</a></sup> Because AI models are context-specific, I would argue, methods for contextualization‚Äîboth quantitative and qualitative‚Äîwill prove necessary for understanding them. LLMs and other AI models are not <em>only</em> bibliographic, but they do refract a sociology of texts that bibliographers can help assemble.</p> <p>To date, much bibliographic study of digital textuality has focused on the materiality of computation‚Äîforensic studies of the hard drive‚Äôs textual inscriptions, for example, or vertical analysis of the layered software and hardware of a single ebook. Matthew Kirschenbaum‚Äôs landmark 2008 book <em>Mechanisms</em> traced both the ‚Äúforensic materiality‚Äù of digital texts‚Äîe.g. the inscription of data onto the substrates of storage media‚Äîand formal materiality, which focuses on the representation of data in different computational systems‚Äîsuch as the ways specific file formats enable and constrain particular uses of data.<sup id="fnref:Kirschenbaum" role="doc-noteref"><a href="#fn:Kirschenbaum" class="footnote" rel="footnote">7</a></sup> It is difficult to know how we might trace the forensic materiality of an LLM‚Äôs output. While the data for LLMs exists somewhere, that existence is far more diffuse, abstract, and distributed than that of a discrete digital document or bound set of files on a particular computer, ebook reader, or server. Even if we had access to the corporate systems that house these models, is the textual data undergirding an LLM inscribed in any single place to which we could point, in the way that bibliographers point to a particular witness of a particular state of a particular edition of a particular book? Most likely not, as the models dynamically construct new texts each time a user prompts them, and these texts‚Äîwhile certainly not immaterial‚Äîare more dynamic and ephemeral than the mutable files on our hard drives.</p> <p>To investigate the forensic materiality of LLMs, then, we should perhaps focus not on specific generated texts, but instead on the infrastructures undergirding AI systems. The field of book history was in many ways founded on Robert Darnton‚Äôs argument that the study of books should investigate the ‚Äúcommunications circuit that runs from the author to the publisher‚Ä¶the printer, the shipper, the bookseller, and the reader,‚Äù an idea (and diagram) that has been much debated and amended since, but which remains central to the field‚Äôs work.<sup id="fnref:Darnton" role="doc-noteref"><a href="#fn:Darnton" class="footnote" rel="footnote">8</a></sup> To understand similar facets of AI systems, we could take as exemplars pieces like Kate Crawford and Vladan Joler‚Äôs ‚ÄúAnatomy of an AI System,‚Äù in which they seek to outline every element required for an Amazon Alexa device to answer a question, from the data model to the minerals mined to create the hardware.<sup id="fnref:AnatomyAI" role="doc-noteref"><a href="#fn:AnatomyAI" class="footnote" rel="footnote">9</a></sup> As <a href="https://liu.english.ucsb.edu/toward-critical-infrastructure-studies-u-connecticut/" target="_blank" rel="noopener noreferrer">Alan Liu has argued</a>, cultural studies and critical infrastructure studies collapse into each other. In the twenty-first-century, this communications circuit has fused with the supply chain, and an analysis of contemporary textual systems like LLMs requires a more capacious account still.</p> <p>If we prompt ChatGPT itself to describe its underlying hardware, its returns a cryptically generic answer:</p> <blockquote> <p>According to a 2020 blog post by OpenAI, ChatGPT-3 (which is a larger version of the model that powers ChatGPT) runs on clusters of thousands of individual CPUs and GPUs, which are distributed across multiple data centers. The specific hardware configurations used in these clusters can vary depending on the specific task being performed by the model and the availability of different hardware components at any given time. OpenAI has also stated that its hardware infrastructure uses a combination of custom-built hardware and off-the-shelf components from vendors such as Nvidia and Intel. This allows the organization to optimize its systems for the specific needs of its AI models while also taking advantage of the latest advances in commercial hardware technology.</p> </blockquote> <p>From here the reply notes ‚Äúthe specific hardware used to power ChatGPT and other OpenAI models is a closely guarded secret, as the organization sees its hardware infrastructure as a key competitive advantage in the field of AI research.‚Äù While we may not be able to learn from ChatGPT or OpenAI‚Äôs publications the precise make and model of the hardware on which ChatGPT runs, as a category such hardware also is not a profound mystery. We can make reasonable assumptions about the kinds of machines required to host and process data at this scale, or serve the model through a web application to users. A basic search for ‚ÄúGPT-3 hardware‚Äù will surface many experts attempting to estimate the precise stack that would be required to run the ChatGPT service, whether in more formal articles, social media threads, or Reddit forums, and publications by the teams behind different models‚Äîparticularly older models, where there is less need for competitive secrecy‚Äîoffer more specific details.<sup id="fnref:Brown" role="doc-noteref"><a href="#fn:Brown" class="footnote" rel="footnote">10</a></sup></p> <p>Similar publications also offer insight into the training data behind LLMs. For instance, a 2022 paper by OpenAI researchers describes the development of InstructGPT, an essential element of the model underlying ChatGPT which improved responsiveness to prompts by hiring human ‚Äúlabelers‚Äù to annotate responses from the model.<sup id="fnref:instruct" role="doc-noteref"><a href="#fn:instruct" class="footnote" rel="footnote">11</a></sup> These labels assigned value to responses that labelers found more or less useful, and were used to finetune the model to produce responses more similar to those preferred by human annotators. This small detail is key to understanding ChatGPT not as a fully automated computational system, but an iteratively-developed system with humans in the loop. Were we to diagram the communications circuit underlying ChatGPT, in other words, we would include labelers, as an important human element within the AI system, along with the low-wage workers in Kenya that <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/" target="_blank" rel="noopener noreferrer">a <em>Time</em> magazine expose</a> found OpenAI using to help filter toxic content. Following McKenzie, our AI bibliography must include the many communities of human labor that contribute to each layer of these technical systems.</p> <p>Several of my examples thus far have pointed to the hybrid communities of field experts, practitioners, and hobbyists working to collectively assemble knowledge about the training data and algorithmic processes of large AI models like GPT, often assembling cumulative insight through channels such as Twitter threads, Reddit fora, or linked Github repositories. I understand these efforts through a set of approaches increasingly advocated by ethicists, such as reverse engineering, data archaeology, and algorithmic auditing. We can distinguish these approaches mostly by their explicit goals, as the methods and results of all three overlap:</p> <ol> <li>Reverse engineering is the broadest term, encompassing a range of projects that seek to understand the processes within a closed, undescribed, or ‚Äúblack box‚Äù system by dissecting, when possible, or by collating indirect evidence when direct access is unavailable. Reverse engineering happens outside of computational contexts, including even when companies seek to copy a successful product made by a competitor. In terms of software, however, reverse engineering may involve studying code and data, when available, to ascertain how it works, or when that is not possible comparing inputs and outputs to infer what happens within the system. As James A. Hodges and Ciaran B. Trace show in their recent article ‚ÄúPreserving Algorithmic Systems,‚Äù ‚Äúattempts at achieving accountability for algorithms are hampered by factors ranging from commercial developers‚Äô profit motives to the simple obscuring effects of time‚Äù and thus often ‚Äúalgorithmic functionality must be reverse-engineered.‚Äù<sup id="fnref:hodges" role="doc-noteref"><a href="#fn:hodges" class="footnote" rel="footnote">12</a></sup> Reverse engineering is essentially what analytical bibliographers do for bookish objects when they use physical clues to understand how those objects were designed and created.</li> <li>Data archaeology is a narrower concept describing attempts to thoroughly document a technical system‚Äîincluding its hardware, data composition, and software processes‚Äîfor future developers or scholars, with an eye toward enabling replication. For example, Benjamin Lee‚Äôs recent_DHQ_ article traces the entwined technical and social stack enabling the <a href="https://labs.loc.gov/work/experiments/newspaper-navigator/" target="_blank" rel="noopener noreferrer"><em>Newspaper Navigator</em> project</a> he developed as the Innovator-in-Residence at the Library of Congress Labs.<sup id="fnref:lee" role="doc-noteref"><a href="#fn:lee" class="footnote" rel="footnote">13</a></sup> As Lee writes, formal data archeologies are written by scholars ‚Äúin support of‚Ä¶call[s] for transparency and responsible stewardship‚Äù in computational research and represent an ideal for data-rich scholarship.</li> <li>Algorithmic auditing focuses more specifically on identifying and mitigating harm perpetuated by automated systems, often with the goal of identifying implicit bias within systems. This sometimes happens proactively, when a company or organization takes steps to review the impacts of software to ensure they are not inadvertently marginalizing particular groups or identities. However, there is a growing body of scholarship that works to audit the processes of less forthright organizations, often through reverse engineering. Consider Safiya Noble‚Äôs <em>Algorithms of Oppression</em>, which reverse engineered the ways Google‚Äôs page rank algorithm reinforced racism through iterative search: comparing results to a range of search terms to understand subtle (and not so subtle) differences in the ways data about different racial groups was sorted and presented to users.<sup id="fnref:noble" role="doc-noteref"><a href="#fn:noble" class="footnote" rel="footnote">14</a></sup> </li> </ol> <p>When corporate secrecy or negligence prevent transparency, efforts to reverse engineer algorithmic systems provide valuable evidence for bibliographies of AI systems. Consider <a href="https://gist.github.com/veekaybee/6f8885e9906aa9c5408ebe5c7e870698" target="_blank" rel="noopener noreferrer">Vicki Boykis‚Äô notebook ‚ÄúEverything I understand about chatgpt,‚Äù</a> which attempts to collate both official and community documentation and outline a theory of ChatGPT‚Äôs training data and architecture. For example, Boykis highlights two components of training data named but not described in OpenAI‚Äôs publications, intriguingly titled <code class="language-plaintext highlighter-rouge">Books1</code> and <code class="language-plaintext highlighter-rouge">Books2</code>, and points to literature describing the development of <code class="language-plaintext highlighter-rouge">BookCorpus</code>, which community investigators believe likely constitutes <code class="language-plaintext highlighter-rouge">Books1</code>. Boykis links both to formal publications, such as <a href="http://arxiv.org/abs/2105.05241" target="_blank" rel="noopener noreferrer">Jack Bandy and Nicholas Vincent‚Äôs ‚ÄúRetrospective Datasheet for BookCorpus‚Äù</a>, as well as to work by people such as Shawn Presser, who <a href="https://github.com/soskek/bookcorpus/issues/27#issuecomment-716104208" target="_blank" rel="noopener noreferrer">provides access to the 18,000 plain text files</a> that make up <code class="language-plaintext highlighter-rouge">bookcorpus</code>. These assembled resources allow researchers to explore at least some of the data thought to compose ChatGPT‚Äôs training corpora.</p> <p>Alongside proprietary AI software, there is also a growing community of open-source models that can serve as proxies for understanding closed models. <a href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" target="_blank" rel="noopener noreferrer">Databricks‚Äô Dolly</a>, for instance, sought to reverse-engineer the ‚Äúinstruction-following behavior‚Äù of InstructGPT and create a ‚Äútruly open large language model‚Äù that would serve their customers who told the company they ‚Äúwould be best served by owning their models, allowing them to create higher quality models for their domain specific applications without handing their sensitive data over to third parties.‚Äù But Databricks also offers ethical reasons for creating this dataset, noting that ‚Äúthe important issues of bias, accountability and AI safety should be addressed by a broad community of diverse stakeholders rather than just a few large companies.‚Äù Looking beyond these stated reasons, the creation of such open-access mirrors of closed corporate systems provides a comparative framework for bibliographies of AI systems. We could investigate the prompts and responses recorded in Dolly‚Äôs training data in order to reconstruct <em>how</em> the data underlying a platform like ChatGPT is likely structured.</p> <p>One principle for bibliographical investigation of AI will be iteration and collection. Users can probe the boundaries and assumptions of an LLM by simply asking variations on particular questions and observing the model‚Äôs responses. This is a form of close reading that seeks not to understand the full system, but to reverse engineer one small facet of the system, with a goal‚Äîperhaps‚Äîof collecting many such examples to build a wider knowledge base. In <a href="https://s23bl.ryancordell.org/lab/2023/01/26/lab2.html" target="_blank" rel="noopener noreferrer">an assignment in my BookLab graduate seminar</a>, for instance, I encouraged students to compare the outputs of different LLMs to the same prompt in order to hypothesize about how their training data is composed or how their models differ; to make incremental changes to prompts within a model to see how that changes the output; to evaluate the responses of LLMs to domains students knew well, to ascertain the veracity of the model‚Äôs data; and to interrogate ‚Äúlimit cases‚Äù that push a model beyond its capabilities. One student found ChatGPT incapable of producing bilingual text‚Äîat least in the hybrid, fast code switching way she wanted to see‚Äîproducing instead text that switched languages by paragraph. Other students struggled against the guardrails OpenAI has placed on the application‚Äînot, importantly, the model itself‚Äîto produce an ‚Äúinsult‚Äù or ‚Äúdiss track.‚Äù While the GPT language model is perfectly capable of assembling negative language, OpenAI restricts such language in order to prevent the internet from internetting. Such discrete limit testing will not produce a theory of ChatGPT writ large, but the accumulation of such tests can begin filling out a picture of what kinds of texts comprise its training data and the ways the model has been fine tuned to enable certain kinds of outputs and prevent others.</p> <p>This iterative approach is also amenable to computational investigation. At the beginning of this talk I compared the textual remixing of LLMs, which I described as ‚Äúpastiche engines,‚Äù with the historical newspaper reprinting we study in <em>Viral Texts</em>. Given that similarity, the reprint detection methods we use for tracing historical reprinting might offer an apporach to reverse engineering an LLM like GPT. I won‚Äôt belabor an explanation of those methods here, but we detail them in the second chapter, <a href="https://manifold.umn.edu/read/untitled-883630b9-c054-44e1-91db-d053a7106ecb/section/ea1f849a-bac1-4e9d-85f4-149d0083a6a4" target="_blank" rel="noopener noreferrer">‚ÄúTextual Criticism as Language Modeling‚Äù</a> of our Manifold scholar book, <em>Going the Rounds</em>. In extreme brief, however, we use a fuzzy matching method that identifies sets of duplicated phrases across texts. The texts do not have to match from end to end, but simply contain enough matching phrases to be flagged as ‚Äúthe same‚Äù by our algorithm.</p> <p>While LLMs assemble text probabilistically, drawing on a wide range of textual sources, they nevertheless retain signals from their training data. If asked to write about a given topic, the words most likely to follow other words will bear a resemblance to the words that follow other words in training data about that topic. This is one reason that users have observed instances of plagiarism in LLM output. Often the best sequence of words‚Äîfrom the perspective of a language model at least‚Äîis precisely the sequence of words in an existing source, particularly for topics without wide coverage in the model‚Äôs training data.</p> <p>To observe this on a small scale, I used the GPT-4 API to generate texts on various topics and then compared ngrams‚Äîsequences of n words length‚Äîbetween the generated texts and potential open-access sources. When I asked for a biography of nineteenth-century American author Fanny Fern,<sup id="fnref:appendixA" role="doc-noteref"><a href="#fn:appendixA" class="footnote" rel="footnote">15</a></sup> for example, I found that the generated biography shared 57 matching 4-grams with <a href="https://en.wikipedia.org/wiki/Fanny_Fern" target="_blank" rel="noopener noreferrer">Fern‚Äôs Wikipedia page</a>, 21 matching 4-grams with the biography on the <a href="https://fannyfern.org/bio" target="_blank" rel="noopener noreferrer"><em>Fanny Fern in the New York Ledger</em></a> DH project website, 24 with Fern‚Äôs bio on the <a href="https://www.womenhistoryblog.com/2011/12/fanny-fern.html" target="_blank" rel="noopener noreferrer">History of American Women</a> site, 27 with Fern‚Äôs entry at <a href="https://www.encyclopedia.com/women/encyclopedias-almanacs-transcripts-and-maps/fern-fanny-1811-1872" target="_blank" rel="noopener noreferrer">Encyclopedia.com</a>, and none with a <a href="https://faculty.georgetown.edu/bassr/heath/syllabuild/iguide/fern.html" target="_blank" rel="noopener noreferrer">Georgetown University bio</a> of Fern. Similarly, a prompt asking for a definition and history of the sonnet returned an answer that shared 26 4-grams with entries on the sonnet in <a href="https://en.wikipedia.org/wiki/Sonnet" target="_blank" rel="noopener noreferrer">Wikipedia</a>, 8 with <a href="https://poets.org/glossary/sonnet" target="_blank" rel="noopener noreferrer">Poets.org</a>, 14 with <a href="https://www.britannica.com/art/sonnet" target="_blank" rel="noopener noreferrer">Encyclopedia Britannica</a>, 13 with the <a href="https://www.poetryfoundation.org/learn/glossary-terms/sonnet" target="_blank" rel="noopener noreferrer">Poetry Foundation</a>, and 11 with <a href="https://www.thoughtco.com/what-is-a-sonnet-2985266" target="_blank" rel="noopener noreferrer">ThoughtCo</a>.<sup id="fnref:appendixB" role="doc-noteref"><a href="#fn:appendixB" class="footnote" rel="footnote">16</a></sup> These examples are idiosyncratic and partial‚Äîproofs of concept‚Äîbut more sustained and systematic work along these lines is both possible and necessary.</p> <p>In fact, even as I was making these small experiments the <em>Washington Post</em> published a collaborative investigation, with the Allen Institute for AI, which takes a very similar approach to reverse engineer the sources of Google‚Äôs C4 dataset.<sup id="fnref:wapo" role="doc-noteref"><a href="#fn:wapo" class="footnote" rel="footnote">17</a></sup> C4, by the way, stands for <a href="https://www.semanticscholar.org/paper/Documenting-the-English-Colossal-Clean-Crawled-Dodge-Sap/40c3327a6ddb0603b6892344509c7f428ab43d81?itid=lk_inline_enhanced-template" target="_blank" rel="noopener noreferrer">Colossal Clean Crawled Corpus</a>, which is a fact I just had to share. To determine which open websites were crawled, the researchers ‚Äúranked the remaining 10 million websites based on how many ‚Äòtokens‚Äô appeared from each in the data set. Tokens are small bits of text used to process disorganized information‚Äîtypically a word or phrase.‚Äù As in my smaller experiments, they find that Wikipedia is by far the largest source, but as they note others that are less obvious,</p> <blockquote> <p>Some top sites seemed arbitrary,like wowhead.com No. 181, a World of Warcraft player forum; thriveglobal.com No. 175, a product for beating burnout founded by Arianna Huffington; and at least 10 sites that sell dumpsters, including dumpsteroid.com No. 183, that no longer appear accessible.</p> </blockquote> <p>The <em>Post</em> article provides a tool that enables readers to enter a domain to see how many of its tokens it shares with the C4 dataset, which signals how likely it was to have contributed to the corpus.</p> <p>The goal for research along these lines cannot be to prove definitely that a particular model draws on this source or that, though such trends may emerge for more influential sources. Instead, the goal should be to generate probabilities about different potential sources: a speculative analytical or descriptive bibliography that gives us a framework for hypotheses and analysis. To return to my initial claims, it is precisely here that I think bibliographical traditions offer helpful analogs. Though some bibliographers have conceived of their work as empirical, in reality every collation formula is a speculation, though one informed by physical evidence. Just as the industrial processes of print culture left traces that we can use to theorize about physical texts‚Äô production and use, the computational processes of digital culture leave traces we can use to theorize about AI texts.</p> <p>Bringing together bibliographical and computational approaches allows us to perceive AI systems not as unknowable oracles but instead bound, describable, and comparable cultural artifacts. Bibliography‚Äôs close attention to understanding and describing the combined material, technological, economic, and social facets of cultural production are precisely what is lacking in much tech discourse in 2023, and are precisely what is needed both to understand the shifts we are undergoing and to advocate for more transparency and responsive systems in the future. In making this argument I am not trying to claim large language models for bibliography, and there are certainly other AI systems that demand distinct expertise. But to the extent that language models are textual media that both draw on and contribute to book culture, they should be the province of bibliographers working in close collaboration with computer scientists, information scientists, technologists, and related experts. AI systems require a bibliography that takes serious the diffuse and often obscured sociology of textual data.</p> <hr> <h2 id="appendix-a-gpt-4-bio-of-fanny-fern">Appendix A: GPT-4 Bio of Fanny Fern</h2> <p>Fanny Fern: A Biography</p> <p>Early Life</p> <p>Fanny Fern, born Sara Payson Willis on July 9, 1811, in Portland, Maine, was an American novelist, journalist, and feminist activist. She was the fourth of nine children born to Nathaniel and Hannah Willis. Her father was a newspaper publisher and writer, which played a pivotal role in Fern‚Äôs interest in writing.</p> <p>In her early life, Fern, like her siblings, was educated at Catherine Beecher‚Äôs boarding school in Hartford, Connecticut. Following her education, she returned to Boston, where her family had moved, and began teaching at a local school.</p> <p>Personal Life</p> <p>Fanny Fern married banker Charles Eldredge in 1837, and together they had three children, Mary Stace, Grace, and Ellen Willis Eldredge. Tragically, Charles died of typhoid fever in 1846, leaving Fern to support her family alone.</p> <p>In 1849, Fern remarried to Samuel P. Farrington, a merchant. However, the marriage was unhappy, and the couple divorced in 1851. Following her divorce, Fern decided to seek financial independence through her writing to support herself and her children.</p> <p>Career</p> <p>In 1851, adopting the pen name Fanny Fern, she began writing essays, sketches, and short stories for several newspapers and periodicals, including ‚ÄúThe Olive Branch‚Äù and ‚ÄúTrue Flag.‚Äù These writings won her a widespread reputation as a courageous, witty, and insightful writer who addressed prevailing social issues, such as women‚Äôs rights, marriage, education, and labor rights.</p> <p>Despite facing criticism from her male counterparts and dealing with societal norms of that time, Fern‚Äôs perseverance led to significant accomplishments. In 1853, she published her first collection, ‚ÄúFern Leaves from Fanny‚Äôs Portfolio,‚Äù which sold over 70,000 copies in its first year. Several more volumes of ‚ÄúFern Leaves‚Äù soon followed.</p> <p>Fanny Fern‚Äôs career as a writer took a leap forward in 1855 when she joined the ‚ÄúNew York Ledger‚Äù as a columnist. She became the highest-paid columnist in the United States at that time, earning $100 per week. Her column, filled with satirical and humorous commentary on contemporary social issues, made her a household name.</p> <p>In 1856, she remarried again, to newspaper editor and biographer James Parton, who encouraged her literary career. Her novel ‚ÄúRuth Hall,‚Äù published that same year, is largely autobiographical, chronicling the struggles of a young widow trying to support her children through writing. It became a bestseller and was praised for its realistic portrayal of women‚Äôs experiences.</p> <p>Later Years and Legacy</p> <p>Fern continued to write for the ‚ÄúNew York Ledger‚Äù and authored more novels, such as ‚ÄúRose Clark‚Äù (1856) and ‚ÄúFolly as It Flies‚Äù (1868). While her popularity diminished in the late 19th century, she made a significant contribution to American literature from a female perspective.</p> <p>Fanny Fern died of cancer in New York City on October 10, 1872, at the age of 61. Today, she is celebrated as a pioneer in feminist writing, and her works have inspired generations of women writers to explore themes that were considered taboo in her time.</p> <h2 id="appendix-b-gpt-4-description-of-the-sonnet">Appendix B: GPT-4 Description of the Sonnet</h2> <p>The sonnet is a poetic form that consists of 14 lines, known for exploring themes of love, beauty, and the passage of time, though it has also been used to address a variety of other subjects. It is believed to have originated in Italy in the 13th century and was later popularized by the Italian poet Petrarch in the 14th century. Petrarch‚Äôs sonnets, written in Italian, primarily focused on his unrequited love for a woman named Laura. Throughout the years, the sonnet has evolved, and its structure and rhyme schemes have adapted to the preferences of different poets and languages.</p> <p>The sonnet is typically written in iambic pentameter, a metrical pattern consisting of five pairs of stressed and unstressed syllables per line. There are two main types of sonnets: the Italian (or Petrarchan) sonnet and the English (or Shakespearean) sonnet.</p> <p>The Italian sonnet is divided into two parts: the octave, which consists of the first eight lines, and the sestet, which includes the remaining six lines. The octave presents a problem, situation, or question, while the sestet resolves or comments on it. The rhyme scheme for the octave is usually ABBAABBA, while the sestet has various rhyme patterns, such as CDECDE or CDCDCD.</p> <p>The English sonnet, on the other hand, is organized into three quatrains, each comprising four lines, and a final rhymed couplet. The rhyme scheme for this type of sonnet is ABABCDCDEFEFGG. The three quatrains often introduce different aspects or develop a single idea, while the final couplet offers a conclusion, a twist or a resolution to the preceding lines.</p> <p>As the sonnet spread from Italy to England in the 16th century, it was embraced and developed by English Renaissance poets like Sir Thomas Wyatt, Edmund Spenser, and, most notably, William Shakespeare. Shakespeare composed a total of 154 sonnets, which cover themes of love, beauty, and the transient nature of life.</p> <p>The sonnet form continued to thrive in the 17th century through the works of poets like John Donne and Milton, and it has remained a popular form among poets throughout history. Romantic poets like William Wordsworth, John Keats, and Percy Bysshe Shelley reinvigorated the form in the 19th century; more recently, in the 20th and 21st centuries, it was seen in the works of poets like Elizabeth Barrett Browning, e. e. cummings, and Seamus Heaney.</p> <p>In summary, the sonnet form is a 14-line poem renowned for its exploration of love, beauty, and time. Though it originated in Italy, it has since been embraced and adapted by poets across the world, evolving through various rhyme schemes and structures while maintaining its distinctive essence.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:ChatGPT" role="doc-endnote"> <p>For OpenAI‚Äôs introduction to ChatGPT, see <a href="https://openai.com/blog/chatgpt/" target="_blank" rel="noopener noreferrer">https://openai.com/blog/chatgpt/</a>. For the best description I have found thus far about how a system like ChatGPT produces language, see Stephen Wolfram‚Äôs post ‚ÄúWhat Is ChatGPT Doing ‚Ä¶ and Why Does It Work?‚Äù <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" target="_blank" rel="noopener noreferrer">https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/</a>.¬†<a href="#fnref:ChatGPT" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:ChatGPTDebate" role="doc-endnote"> <p>An overview of the latter debate can be found in Susan D‚ÄôAgostino‚Äôs <em>Inside Higher Ed</em> article ‚ÄúChatGPT Advice Academics Can Use Now‚Äù (12 January 2023) which includes interviews with faculty across the spectrum of enthusiasm to skepticism: <a href="https://www.insidehighered.com/news/2023/01/12/academic-experts-offer-advice-chatgpt" target="_blank" rel="noopener noreferrer">https://www.insidehighered.com/news/2023/01/12/academic-experts-offer-advice-chatgpt</a>¬†<a href="#fnref:ChatGPTDebate" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:GPT4" role="doc-endnote"> <p>See <a href="https://openai.com/product/gpt-4" target="_blank" rel="noopener noreferrer">https://openai.com/product/gpt-4</a> for the official description of GPT-4 from OpenAI.¬†<a href="#fnref:GPT4" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:McKenzie" role="doc-endnote"> <p>D. F McKenzie, <em>Bibliography and the Sociology of Texts</em> (Cambridge: Cambridge University Press, 2004), pg. 13.¬†<a href="#fnref:McKenzie" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:speculative" role="doc-endnote"> <p>Ryan Cordell, ‚ÄúSpeculative Bibliography,‚Äù <em>Anglia</em> 138, no. 3 (September 15, 2020): 519‚Äì31, <a href="https://doi.org/10.1515/ang-2020-0041" target="_blank" rel="noopener noreferrer">https://doi.org/10.1515/ang-2020-0041</a>.¬†<a href="#fnref:speculative" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:underwood" role="doc-endnote"> <p>Ted Underwood, ‚ÄúWhy an Age of Machine Learning Needs the Humanities,‚Äù <em>Public Books</em> (blog), December 5, 2018, <a href="https://www.publicbooks.org/why-an-age-of-machine-learning-needs-the-humanities/" target="_blank" rel="noopener noreferrer">https://www.publicbooks.org/why-an-age-of-machine-learning-needs-the-humanities/</a>.¬†<a href="#fnref:underwood" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Kirschenbaum" role="doc-endnote"> <p>Matthew G Kirschenbaum, <em>Mechanisms: New Media and the Forensic Imagination</em> (Cambridge, Mass.: MIT Press, 2008).¬†<a href="#fnref:Kirschenbaum" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Darnton" role="doc-endnote"> <p>Robert Darnton, ‚ÄúWhat Is the History of Books?,‚Äù <em>Daedalus</em> 111, no. 3 (July 1, 1982): 65‚Äì83.¬†<a href="#fnref:Darnton" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:AnatomyAI" role="doc-endnote"> <p>Kate Crawford and Vladan Joler, ‚ÄúAnatomy of an AI System: The Amazon Echo As An Anatomical Map of Human Labor‚Äù (AI Now Institute and Share Lab, September 7, 2018), <a href="http://www.anatomyof.ai" target="_blank" rel="noopener noreferrer">http://www.anatomyof.ai</a>.¬†<a href="#fnref:AnatomyAI" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:Brown" role="doc-endnote"> <p>Tom B. Brown et al., ‚ÄúLanguage Models Are Few-Shot Learners‚Äù (arXiv, July 22, 2020), http://arxiv.org/abs/2005.14165.¬†<a href="#fnref:Brown" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:instruct" role="doc-endnote"> <p>Long Ouyang et al., ‚ÄúTraining Language Models to Follow Instructions with Human Feedback‚Äù (arXiv, March 4, 2022), http://arxiv.org/abs/2203.02155.¬†<a href="#fnref:instruct" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:hodges" role="doc-endnote"> <p>James A. Hodges and Ciaran B. Trace, ‚ÄúPreserving Algorithmic Systems: A¬†Synthesis of Overlapping Approaches, Materialities and Contexts,‚Äù <em>Journal of Documentation</em> ahead-of-print, no. ahead-of-print (January 1, 2023), <a href="https://doi.org/10.1108/JD-09-2022-0204" target="_blank" rel="noopener noreferrer">https://doi.org/10.1108/JD-09-2022-0204</a>.¬†<a href="#fnref:hodges" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:lee" role="doc-endnote"> <p>Benjamin Lee, ‚ÄúCompounded Mediation: A Data Archaeology of the Newspaper Navigator Dataset,‚Äù <em>Digital Humanities Quarterly</em> 015, no. 4 (2021), <a href="http://www.digitalhumanities.org/dhq/vol/15/4/000578/000578.html" target="_blank" rel="noopener noreferrer">http://www.digitalhumanities.org/dhq/vol/15/4/000578/000578.html</a>.¬†<a href="#fnref:lee" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:noble" role="doc-endnote"> <p>Safiya Noble, <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>, (New York: NYU Press, 2018).¬†<a href="#fnref:noble" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:appendixA" role="doc-endnote"> <p>I have copied the full Fanny Fern biography generated by GPT-4 in Appendix A.¬†<a href="#fnref:appendixA" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:appendixB" role="doc-endnote"> <p>I have copied the full text generated by GPT-4 about the sonnet in Appendix B¬†<a href="#fnref:appendixB" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> <li id="fn:wapo" role="doc-endnote"> <p>Kevin Schaul, Szu Yu Chen, and Nitasha Tiku, ‚ÄúInside the Secret List of Websites That Make AI like ChatGPT Sound Smart,‚Äù Washington Post, April 19, 2023, <a href="https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/" target="_blank" rel="noopener noreferrer">https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/</a>.¬†<a href="#fnref:wapo" class="reversefootnote" role="doc-backlink">‚Ü©</a></p> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Ryan C. Cordell. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>